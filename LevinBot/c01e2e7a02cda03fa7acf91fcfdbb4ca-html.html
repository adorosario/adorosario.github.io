<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
<title>c01e2e7a02cda03fa7acf91fcfdbb4ca-html.html</title>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
 <br/>
<style type="text/css">
<!--
	p {margin: 0; padding: 0;}	.ft10{font-size:11px;font-family:Times;color:#231f20;}
	.ft11{font-size:7px;font-family:Times;color:#231f20;}
	.ft12{font-size:8px;font-family:Times;color:#231f20;}
	.ft13{font-size:10px;font-family:Times;color:#231f20;}
	.ft14{font-size:16px;font-family:Times;color:#231f20;}
	.ft15{font-size:28px;font-family:Times;color:#231f20;}
	.ft16{font-size:19px;font-family:Times;color:#231f20;}
	.ft17{font-size:10px;font-family:Times;color:#231f20;}
	.ft18{font-size:11px;font-family:Times;color:#231f20;}
	.ft19{font-size:12px;font-family:Times;color:#231f20;}
	.ft110{font-size:15px;font-family:Times;color:#231f20;}
	.ft111{font-size:8px;font-family:Times;color:#231f20;}
	.ft112{font-size:8px;font-family:Times;color:#231f20;}
	.ft113{font-size:19px;line-height:27px;font-family:Times;color:#231f20;}
	.ft114{font-size:10px;line-height:16px;font-family:Times;color:#231f20;}
	.ft115{font-size:11px;line-height:16px;font-family:Times;color:#231f20;}
	.ft116{font-size:12px;line-height:19px;font-family:Times;color:#231f20;}
-->
</style>
</head>
<body bgcolor="#A0A0A0" vlink="blue" link="blue">
<div id="page1-div" style="position:relative;width:892px;height:1173px;">
<p style="position:absolute;top:1108px;left:400px;white-space:nowrap" class="ft10"><b>2002882&#160;&#160;(1 of 12)</b></p>
<p style="position:absolute;top:1112px;left:704px;white-space:nowrap" class="ft11">©&#160;2020 Wiley-VCH GmbH</p>
<p style="position:absolute;top:64px;left:743px;white-space:nowrap" class="ft13"><b>www<a href="http://crossmark.crossref.org/dialog/?doi=10.1002%2Fadma.202002882&domain=pdf&date_stamp=2020-09-21">.advmat.de</a></b></p>
<p style="position:absolute;top:31px;left:77px;white-space:nowrap" class="ft14"><b>Progress&#160;rePort</b></p>
<p style="position:absolute;top:101px;left:77px;white-space:nowrap" class="ft15"><b>Shape Changing Robots: Bioinspiration, Simulation, and&#160;</b></p>
<p style="position:absolute;top:135px;left:77px;white-space:nowrap" class="ft15"><b>Physical Realization</b></p>
<p style="position:absolute;top:189px;left:77px;white-space:nowrap" class="ft113"><i>Dylan Shah, Bilige Yang, Sam Kriegman, Michael Levin, Josh Bongard,&#160;<br/>and Rebecca Kramer-Bottiglio*</i></p>
<p style="position:absolute;top:768px;left:77px;white-space:nowrap" class="ft17">D. Shah, B. Yang, Prof. R. Kramer-Bottiglio</p>
<p style="position:absolute;top:782px;left:77px;white-space:nowrap" class="ft17">School of Engineering &amp; Applied Science</p>
<p style="position:absolute;top:795px;left:77px;white-space:nowrap" class="ft17">Yale University</p>
<p style="position:absolute;top:809px;left:77px;white-space:nowrap" class="ft17">9 Hillhouse Avenue, New Haven, CT 06511, USA</p>
<p style="position:absolute;top:822px;left:77px;white-space:nowrap" class="ft114">E-mail:&#160;rebecca.kramer@yale.edu<br/>S. Kriegman, Prof. J. Bongard</p>
<p style="position:absolute;top:852px;left:77px;white-space:nowrap" class="ft17">Department of Computer Science</p>
<p style="position:absolute;top:866px;left:77px;white-space:nowrap" class="ft17">University of Vermont</p>
<p style="position:absolute;top:879px;left:77px;white-space:nowrap" class="ft114">E428 Innovation Hall, Burlington, VT 05405, USA<br/>Prof. M. Levin</p>
<p style="position:absolute;top:909px;left:77px;white-space:nowrap" class="ft17">Department of Biology</p>
<p style="position:absolute;top:923px;left:77px;white-space:nowrap" class="ft17">Allen Discovery Center at Tufts University&#160;</p>
<p style="position:absolute;top:936px;left:77px;white-space:nowrap" class="ft17">Tufts University</p>
<p style="position:absolute;top:950px;left:77px;white-space:nowrap" class="ft114">200 Boston Ave. Suite 4604, Medford, MA 02155, USA<br/>Prof. M. Levin</p>
<p style="position:absolute;top:980px;left:77px;white-space:nowrap" class="ft17">Wyss Institute for Biologically Inspired Engineering</p>
<p style="position:absolute;top:993px;left:77px;white-space:nowrap" class="ft17">Harvard University</p>
<p style="position:absolute;top:1007px;left:77px;white-space:nowrap" class="ft17">3 Blackfan Cir, Boston, MA 02115, USA</p>
<p style="position:absolute;top:1025px;left:103px;white-space:nowrap" class="ft17">The ORCID identification number(s) for the author(s) of this article&#160;</p>
<p style="position:absolute;top:1038px;left:103px;white-space:nowrap" class="ft17">can be found under https://doi.org/10.1002/adma.202002882.</p>
<p style="position:absolute;top:1061px;left:77px;white-space:nowrap" class="ft10"><b>DOI:&#160;10.1002/adma.202002882</b></p>
<p style="position:absolute;top:269px;left:578px;white-space:nowrap" class="ft115">are specialized for a single task, and cannot&#160;<br/>adapt their body to accomplish additional&#160;<br/>tasks after manufacture. Moreover,&#160;<br/>biological bodies are often highly regen-<br/>erative, and able to repair and reconfigure&#160;<br/>their large-scale architecture in the face&#160;<br/>of significant damage or radical changes&#160;<br/>to&#160;their&#160;components.[3]&#160;For&#160;example,&#160;sala-<br/>manders regenerate amputated limbs,[4]&#160;<br/>and fragments cut from arbitrary portions&#160;<br/>of planaria flatworms can rebuild (and&#160;<br/>rescale) their bodies to recover a full, cor-<br/>rect&#160;anatomy.[3]&#160;Remarkably,&#160;many&#160;of&#160;these&#160;<br/>systems are able to retain information,&#160;<br/>such&#160;as&#160;learned&#160;memories,&#160;despite&#160;drastic&#160;<br/>reconfiguration or total replacement of their&#160;<br/>brains.[5]&#160;In these integrated living systems,&#160;<br/>intelligence, memory, learning, behavior,&#160;<br/>and body structure are all intertwined and&#160;</p>
<p style="position:absolute;top:582px;left:459px;white-space:nowrap" class="ft115">emerge from the multiscale dynamics of the same robust and&#160;<br/>highly fault-tolerant medium.</p>
<p style="position:absolute;top:615px;left:474px;white-space:nowrap" class="ft18">Evolution did not result in hard-coded body plans purely deter-</p>
<p style="position:absolute;top:632px;left:459px;white-space:nowrap" class="ft115">mined&#160;by&#160;genetic&#160;factors,&#160;but&#160;rather&#160;produced&#160;diverse&#160;examples&#160;of&#160;<br/>intelligent self-modifying systems which adapt to numerous extra-<br/>genomic influences.[6]&#160;In this way, biology serves as an important&#160;<br/>proof-of-principle, and design challenge, for artificial intelligence and&#160;<br/>shape changing robots. Despite having access to this extensive set of&#160;<br/>model systems, the realization of general-purpose, adaptive robots&#160;<br/>has remained elusive. Researchers have proposed modular robots&#160;<br/>that can be attached to each other to expand functionality,[7]&#160;passively&#160;<br/>conforming universal grippers,[8]&#160;reconfigurable robotic skins,[9]&#160;<br/>self-assembling robot swarms,[10]&#160;gait-switching mechanisms[11]&#160;and&#160;<br/>controllers,[12,13]&#160;and algorithms that quickly re-adapt to multiple&#160;<br/>distinct tasks.[14]&#160;Such approaches succeed at adaptation but operate&#160;<br/>under the assumption that the robot’s body is only reconfigured or&#160;<br/>reshaped due to external forces, and do not explore the possibility of&#160;<br/>synthetic machines that actively grow, regenerate, deform, or other-<br/>wise change the resting shape of their constituent components.</p>
<p style="position:absolute;top:896px;left:474px;white-space:nowrap" class="ft18">With the introduction of a conformable gripper by Hirose&#160;</p>
<p style="position:absolute;top:912px;left:459px;white-space:nowrap" class="ft115">in 1978,[15]&#160;followed by continuum robot arms,[16]&#160;silicone&#160;<br/>grippers,[17]&#160;and variable stiffness actuators,[18]&#160;robots that can&#160;<br/>adapt to real-world environments by changing their shape are&#160;<br/>becoming closer to reality. In particular, the idea of passively&#160;<br/>conforming&#160;around objects&#160;during&#160;grasping has&#160;been quite&#160;suc-<br/>cessful.[17,19,20]&#160;Soft robots&#160;have&#160;shown potential&#160;in&#160;other&#160;appli-<br/>cations, including human–robot interaction and exploration,&#160;<br/>as reviewed by Kim et al.,[21]&#160;Rus et al.,[22]&#160;and others.[23,24]&#160;For&#160;<br/>a comprehensive review of the role of deformation in single-<br/>function soft robots, the reader is referred to Wang et al.[25]</p>
<p style="position:absolute;top:280px;left:76px;white-space:nowrap" class="ft116"><b>One of the key differentiators between biological and artificial systems is&#160;<br/>the dynamic plasticity of living tissues, enabling adaptation to different&#160;<br/>environmental conditions, tasks, or damage by reconfiguring physical&#160;<br/>structure and behavioral control policies. Lack of dynamic plasticity is a&#160;<br/>significant limitation for artificial systems that must robustly operate in the&#160;<br/>natural world. Recently, researchers have begun to leverage insights from&#160;<br/>regenerating and metamorphosing organisms, designing robots capable of&#160;<br/>editing their own structure to more efficiently perform tasks under changing&#160;<br/>demands and creating new algorithms to control these changing anatomies.&#160;<br/>Here, an overview of the literature related to robots that change shape to&#160;<br/>enhance and expand their functionality is presented. Related grand challenges,&#160;<br/>including shape sensing, finding, and changing, which rely on innovations&#160;<br/>in multifunctional materials, distributed actuation and sensing, and somatic&#160;<br/>control to enable next-generation shape changing robots are also discussed.</b></p>
<p style="position:absolute;top:581px;left:77px;white-space:nowrap" class="ft110"><b>1. Introduction</b></p>
<p style="position:absolute;top:615px;left:77px;white-space:nowrap" class="ft115">Biological organisms are able to adjust their body structure,&#160;<br/>stiffness, and behavior toward a complex anatomy that accom-<br/>modates a variety of environmental demands and external pertur-<br/>bations. For example, octopuses have been observed to squeeze&#160;<br/>through&#160;apertures that&#160;are&#160;much smaller&#160;than&#160;their&#160;body,&#160;hydro-<br/>static caterpillars use peristaltic shape change to locomote across&#160;<br/>numerous environments,[1]&#160;and moth larvae have been observed&#160;<br/>to curl up to roll away from predators.[2]&#160;In contrast, robots often&#160;</p>
<p style="position:absolute;top:1112px;left:77px;white-space:nowrap" class="ft111"><i>Adv.</i>&#160;<i>Mater.</i>&#160;<b>2020</b>, 2002882</p>
</div>
</body>
</html>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
<title>c01e2e7a02cda03fa7acf91fcfdbb4ca-html.html</title>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
 <br/>
<style type="text/css">
<!--
	p {margin: 0; padding: 0;}	.ft20{font-size:7px;font-family:Times;color:#231f20;}
	.ft21{font-size:8px;font-family:Times;color:#231f20;}
	.ft22{font-size:11px;font-family:Times;color:#231f20;}
	.ft23{font-size:10px;font-family:Times;color:#231f20;}
	.ft24{font-size:11px;font-family:Times;color:#231f20;}
	.ft25{font-size:10px;font-family:Times;color:#000000;}
	.ft26{font-size:10px;font-family:Times;color:#000000;}
	.ft27{font-size:11px;font-family:Times;color:#000000;}
	.ft28{font-size:18px;font-family:Times;color:#000000;}
	.ft29{font-size:15px;font-family:Times;color:#231f20;}
	.ft210{font-size:11px;font-family:Times;color:#231f20;}
	.ft211{font-size:8px;font-family:Times;color:#231f20;}
	.ft212{font-size:8px;font-family:Times;color:#231f20;}
	.ft213{font-size:11px;line-height:16px;font-family:Times;color:#231f20;}
	.ft214{font-size:15px;line-height:30px;font-family:Times;color:#231f20;}
-->
</style>
</head>
<body bgcolor="#A0A0A0" vlink="blue" link="blue">
<div id="page2-div" style="position:relative;width:892px;height:1173px;">
<p style="position:absolute;top:1112px;left:701px;white-space:nowrap" class="ft20">©&#160;2020 Wiley-VCH GmbH</p>
<p style="position:absolute;top:1108px;left:395px;white-space:nowrap" class="ft22"><b>2002882&#160;&#160;(2 of 12)</b></p>
<p style="position:absolute;top:64px;left:739px;white-space:nowrap" class="ft23"><b>www.advmat.de</b></p>
<p style="position:absolute;top:64px;left:72px;white-space:nowrap" class="ft23"><b>www.advancedsciencenews.com</b></p>
<p style="position:absolute;top:104px;left:87px;white-space:nowrap" class="ft24">Several recent works have begun to explore the idea of using&#160;</p>
<p style="position:absolute;top:120px;left:72px;white-space:nowrap" class="ft213">the resting (non-actuated) shape of a robot’s body as a way to&#160;<br/>expand the robot’s functionality. For example, one robot could&#160;<br/>switch between spherical and cylindrical shapes for medical&#160;<br/>applications such as navigating the digestive system.[26,27]&#160;<br/>Another robot used origami techniques to change the diameter&#160;<br/>of its wheels to crawl over steps and under overhangs.[28]&#160;Nygaard&#160;<br/>et al. introduced a quadrupedal robot that adjusted its leg length&#160;<br/>to maximize locomotion speed across different surfaces.[29]&#160;In&#160;<br/>another recent study, robotic skins were attached to sculptable&#160;<br/>materials to create a robot that could change its shape to navi-<br/>gate over an obstacle, rather than searching for a path around&#160;<br/>the obstacle.[30]&#160;Shape change can also be used to allow robots to&#160;<br/>recover from damage, sometimes outperforming adaptations in&#160;<br/>control policy.[31]&#160;In such examples, even relatively small changes&#160;<br/>in resting body shape proved useful, pointing toward future gen-<br/>eral-purpose&#160;robots&#160;that&#160;leverage&#160;shape&#160;change&#160;to&#160;adapt&#160;to&#160;chal-<br/>lenging real-world environments, as envisioned in&#160;<b>Figure</b> <b>1</b>.</p>
<p style="position:absolute;top:401px;left:87px;white-space:nowrap" class="ft24">Despite&#160;the&#160;intense&#160;interest&#160;in the&#160;genesis&#160;and&#160;implications&#160;</p>
<p style="position:absolute;top:417px;left:72px;white-space:nowrap" class="ft213">of shape for many fields, including medicine,[32]&#160;developmental&#160;<br/>biology,[33]&#160;swarm robotics,[34]&#160;and evolutionary&#160;robotics,[35]&#160;a&#160;<br/>consensus on how to quantify changes in shape has not been&#160;<br/>reached. Taha et al., for instance, reported that 20 distinct shape&#160;<br/>metrics are commonly used for 3D medical image segmenta-<br/>tion.[32]&#160;For robots, one natural approach to measure shape&#160;<br/>change is calculating a virtual “elastic deformation energy,”&#160;<br/>which can be thought of as the energy required to stretch an&#160;<br/>elastic membrane from one shape to another.[36]&#160;However, for&#160;<br/>many robots, it is difficult to generate meshes or analytic expres-<br/>sions to represent their shape in real time, and it is common&#160;<br/>in robotics to quantify shape-estimation errors using a small&#160;<br/>subset&#160;of surface points&#160;and evaluating&#160;root-mean-squared&#160;<br/>error (RMSE) or mean absolute error.[37–42]&#160;Several other dis-<br/>crete measurements of shape similarity have been proposed in&#160;<br/>the robotics community, including Procrustes analysis (a modi-<br/>fication of RMSE that is invariant to rotation, scaling, and trans-<br/>lation errors),[40]&#160;a “shape index” (</p>
<p style="position:absolute;top:699px;left:302px;white-space:nowrap" class="ft25">Perimeter/&#160;2</p>
<p style="position:absolute;top:699px;left:403px;white-space:nowrap" class="ft25">area</p>
<p style="position:absolute;top:699px;left:282px;white-space:nowrap" class="ft26"><i>S</i></p>
<p style="position:absolute;top:697px;left:380px;white-space:nowrap" class="ft27">π</p>
<p style="position:absolute;top:691px;left:361px;white-space:nowrap" class="ft28">(</p>
<p style="position:absolute;top:691px;left:427px;white-space:nowrap" class="ft28">)</p>
<p style="position:absolute;top:697px;left:293px;white-space:nowrap" class="ft25">=</p>
<p style="position:absolute;top:697px;left:390px;white-space:nowrap" class="ft25">×</p>
<p style="position:absolute;top:698px;left:430px;white-space:nowrap" class="ft24">,&#160;&#160;</p>
<p style="position:absolute;top:714px;left:72px;white-space:nowrap" class="ft213">which&#160;does not define&#160;a true metric),[10]&#160;and&#160;the Hausdorff&#160;<br/>distance.[43]</p>
<p style="position:absolute;top:747px;left:87px;white-space:nowrap" class="ft24">Here,&#160;we&#160;will use the&#160;term&#160;“shape&#160;changing&#160;robots”&#160;to&#160;refer&#160;</p>
<p style="position:absolute;top:764px;left:72px;white-space:nowrap" class="ft213">to robots that actively change their shape to adapt to their envi-<br/>ronment or gain new functionalities. Although this defini-<br/>tion does not divide robots into two mutually exclusive sets, it&#160;<br/>provides a framework to critically evaluate the state-of-the-art&#160;<br/>design paradigms and materials used in robotics. Through&#160;<br/>such introspection, and by observing biological mechanisms for&#160;<br/>shape change, we present several avenues where fundamental&#160;<br/>advances in materials science can enable the next generation&#160;<br/>of adaptive, shape changing robots, potentially one day rivaling&#160;<br/>biological systems that locally encode shape information to&#160;<br/>enable dynamic plasticity and regeneration.[33]</p>
<p style="position:absolute;top:981px;left:72px;white-space:nowrap" class="ft213"><b>2. Biological Control of Shape<br/></b>In organisms ranging from flatworms to mammals, hier-<br/>archical processes regulate shape throughout development&#160;<br/>to ensure the organism can succeed in its ecological niche&#160;<br/>throughout its life cycle.[33]&#160;Each normal fertilized egg reliably&#160;</p>
<p style="position:absolute;top:120px;left:634px;white-space:nowrap" class="ft213"><b>Michael Levin</b>&#160;is interested&#160;<br/>in embodiments of mind&#160;<br/>at multiple scales of&#160;<br/>biology and engineering.&#160;<br/>He received B.S. degrees&#160;<br/>in computer science and&#160;<br/>biology, followed by a Ph.D.&#160;<br/>(Harvard University). After a&#160;<br/>post-doc (Harvard Medical&#160;<br/>School), he started his&#160;<br/>independent lab focusing&#160;<br/>on the biophysics of cell:cell&#160;<br/>communication during&#160;</p>
<p style="position:absolute;top:334px;left:470px;white-space:nowrap" class="ft213">embryogenesis, regeneration, and cancer. His group at&#160;<br/>Tufts uses biophysical and computational approaches to&#160;<br/>study decision-making and basal cognition in cells, tissues,&#160;<br/>and artificial living machines. He holds the Vannevar Bush&#160;<br/>chair, and directs the Allen Discovery Center, working&#160;<br/>to crack the morphogenetic code for applications in&#160;<br/>regenerative medicine and machine learning.</p>
<p style="position:absolute;top:473px;left:634px;white-space:nowrap" class="ft213"><b>Josh Bongard</b>&#160;is the Veinott&#160;<br/>Professor of computer&#160;<br/>science at the University of&#160;<br/>Vermont and director of the&#160;<br/>Morphology, Evolution and&#160;<br/>Cognition Laboratory. His&#160;<br/>work involves automated&#160;<br/>design and manufacture&#160;<br/>of soft-, evolved-, and&#160;<br/>crowd-sourced robots, as&#160;<br/>well as computer-designed&#160;<br/>organisms. He is the author&#160;<br/>of the book&#160;<i>How the Body&#160;</i></p>
<p style="position:absolute;top:688px;left:470px;white-space:nowrap" class="ft213"><i>Shapes the Way We Think</i>, the instructor of a Reddit-based&#160;<br/>evolutionary robotics MOOC, and director of the robotics&#160;<br/>outreach program Twitch Plays Robotics.</p>
<p style="position:absolute;top:761px;left:634px;white-space:nowrap" class="ft213"><b>Rebecca Kramer-Bottiglio</b>&#160;<br/>is the John J. Lee Assistant&#160;<br/>Professor of mechanical&#160;<br/>engineering and materials&#160;<br/>science at Yale University.&#160;<br/>Working at the intersection&#160;<br/>of materials, manufacturing,&#160;<br/>and robotics, her group is&#160;<br/>deriving new multifunctional&#160;<br/>materials that will allow&#160;<br/>next-generation robots to&#160;<br/>adapt their morphology and&#160;<br/>behavior to changing tasks&#160;</p>
<p style="position:absolute;top:976px;left:470px;white-space:nowrap" class="ft213">and environments. She is recognized for her approach to&#160;<br/>manufacturing liquid metals through printable dispersions&#160;<br/>and scalable sintering methods and her development&#160;<br/>of robotic skins that turn inanimate objects into&#160;<br/>multifunctional robots.</p>
<p style="position:absolute;top:1112px;left:72px;white-space:nowrap" class="ft211"><i>Adv.</i>&#160;<i>Mater.</i>&#160;<b>2020</b>, 2002882</p>
</div>
</body>
</html>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
<title>c01e2e7a02cda03fa7acf91fcfdbb4ca-html.html</title>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
 <br/>
<style type="text/css">
<!--
	p {margin: 0; padding: 0;}	.ft30{font-size:7px;font-family:Times;color:#231f20;}
	.ft31{font-size:8px;font-family:Times;color:#231f20;}
	.ft32{font-size:11px;font-family:Times;color:#231f20;}
	.ft33{font-size:10px;font-family:Times;color:#231f20;}
	.ft34{font-size:11px;font-family:Times;color:#231f20;}
	.ft35{font-size:15px;font-family:Times;color:#231f20;}
	.ft36{font-size:10px;font-family:Times;color:#231f20;}
	.ft37{font-size:8px;font-family:Times;color:#231f20;}
	.ft38{font-size:8px;font-family:Times;color:#231f20;}
	.ft39{font-size:11px;line-height:16px;font-family:Times;color:#231f20;}
	.ft310{font-size:15px;line-height:30px;font-family:Times;color:#231f20;}
-->
</style>
</head>
<body bgcolor="#A0A0A0" vlink="blue" link="blue">
<div id="page3-div" style="position:relative;width:892px;height:1173px;">
<p style="position:absolute;top:1112px;left:704px;white-space:nowrap" class="ft30">©&#160;2020 Wiley-VCH GmbH</p>
<p style="position:absolute;top:1108px;left:399px;white-space:nowrap" class="ft32"><b>2002882&#160;&#160;(3 of 12)</b></p>
<p style="position:absolute;top:64px;left:743px;white-space:nowrap" class="ft33"><b>www.advmat.de</b></p>
<p style="position:absolute;top:64px;left:77px;white-space:nowrap" class="ft33"><b>www.advancedsciencenews.com</b></p>
<p style="position:absolute;top:401px;left:77px;white-space:nowrap" class="ft39">self-assembles&#160;a&#160;default&#160;3D&#160;anatomical&#160;structure&#160;with&#160;very&#160;<br/>precise tolerances to a standard “target morphology” for that&#160;<br/>species. This process is remarkably robust—for example, mam-<br/>malian embryos can be cut in half and each will result in a&#160;<br/>complete, normal body. In another example, land-based&#160;mam-<br/>malian embryos thrive in an aqueous environment during fetal&#160;<br/>development, yet prior to birth grow skeletal structures more&#160;<br/>suitable for terrestrial locomotion.</p>
<p style="position:absolute;top:533px;left:92px;white-space:nowrap" class="ft34">Regenerative animals provide a unique example of how&#160;</p>
<p style="position:absolute;top:549px;left:77px;white-space:nowrap" class="ft39">shape change can be used to recover from damage. When&#160;<br/>the limbs of a salamander are amputated, the cells are called&#160;<br/>upon to proliferate, perform morphogenesis, and stop when&#160;<br/>a correct salamander limb is complete.[4]&#160;How the cells are&#160;<br/>able to ascertain the current morphology of the much larger&#160;<br/>limb, and continually compare it to an intrinsic model of the&#160;<br/>target limb morphology to control individual cell behaviors&#160;<br/>toward self-limiting repair, is largely unknown.[44]&#160;However,&#160;<br/>it is clear that this somatic decision-making is an ancient,&#160;<br/>pre-neural example of intelligence and distributed compu-<br/>tation in biological systems.[45–47]&#160;The tissue undergoing&#160;<br/>dynamic shape change is the same tissue that is processing&#160;<br/>information on-the-fly and making decisions about growth&#160;<br/>and form. Regenerative systems thus challenge engineers&#160;<br/>to implement a kind of integrated, robust computational&#160;<br/>medium that can continue to guide its own shape even as it&#160;<br/>is being deformed.</p>
<p style="position:absolute;top:830px;left:92px;white-space:nowrap" class="ft34">Recent progress in genomics and molecular biology have&#160;</p>
<p style="position:absolute;top:846px;left:77px;white-space:nowrap" class="ft39">shed crucial light on the origin of biological hardware: genes&#160;<br/>encode signaling and structural components (proteins) at&#160;<br/>the sub-cellular level. However, the genome does not directly&#160;<br/>encode the target morphology, nor the algorithms sufficient&#160;<br/>to perform the kind of error correction seen during regenera-<br/>tion.[6]&#160;The search for the biological software that runs on&#160;<br/>the&#160;genome-specified&#160;hardware&#160;has&#160;only&#160;begun,&#160;and&#160;two&#160;key&#160;<br/>features are now apparent. First, the software is biophysical in&#160;<br/>implementation. Bioelectric networks[48]&#160;enable cell collectives&#160;<br/>to store pattern memories, generate spontaneous symmetry-<br/>breaking morphogenesis, recognize patterns, and integrate&#160;<br/>information&#160;across&#160;large&#160;distances&#160;in&#160;the&#160;body[49]—all&#160;occur-<br/>ring outside the brain. Second, this embodied software strategy&#160;<br/>enables dynamic plasticity. For example, caterpillars that learn&#160;</p>
<p style="position:absolute;top:401px;left:459px;white-space:nowrap" class="ft39">conditioned responses to a chemical in their environment&#160;<br/>retain that information as butterflies, despite complete brain&#160;<br/>reconstruction during metamorphosis.[50]&#160;Planaria retain their&#160;<br/>memories across total brain removal and regeneration.[51,52]&#160;<br/>Oviedo et &#160;al. showed a technique for creating two-headed&#160;<br/>flatworms whose pieces continue to regenerate as two-headed&#160;<br/>forms in subsequent rounds of damage and regrowth without&#160;<br/>further treatment.[53]&#160;Tadpoles&#160;made&#160;to&#160;have&#160;eyes&#160;only&#160;on&#160;their&#160;<br/>tails can see quite well, despite this unprecedented change&#160;<br/>in sensory system architecture.[54]&#160;Next-generation robots&#160;<br/>can learn from these examples of basal cognition coupled to&#160;<br/>physical shape change,[45,55]&#160;perhaps embedding information-<br/>processing tools that guide shape change directly into the&#160;<br/>robot’s body.[56,57]</p>
<p style="position:absolute;top:667px;left:459px;white-space:nowrap" class="ft39"><b>3. Simulated Shape Changing Robots<br/></b>Although numerous organisms successfully exploit shape&#160;<br/>change as a mechanism for adaptation and survival, it is&#160;<br/>unclear&#160;when&#160;and&#160;how&#160;robots&#160;should&#160;change&#160;their&#160;shape.&#160;To&#160;<br/>address these questions, it would be useful to evaluate a large&#160;<br/>number of diverse shape changing robots in different environ-<br/>ments. However, manufacturing and deploying multiple robots&#160;<br/>can be expensive, time consuming, and even dangerous. Thus,&#160;<br/>simulations&#160;are&#160;often used&#160;to&#160;weed out&#160;undesirable&#160;designs&#160;<br/>before attempting to build them in reality.[43,58–60]</p>
<p style="position:absolute;top:846px;left:474px;white-space:nowrap" class="ft34">Yet, under realistic&#160;design conditions,&#160;simulations&#160;cannot&#160;</p>
<p style="position:absolute;top:863px;left:459px;white-space:nowrap" class="ft39">exhaustively search the design space. Even using a small&#160;<br/>number&#160;of&#160;mechanical&#160;parts,&#160;the size&#160;of&#160;the design&#160;space&#160;is&#160;<br/>enormous. For example, in voxel-based robot simulators,[61,62]&#160;<br/>which use voxels as structural building blocks, there are&#160;</p>
<p style="position:absolute;top:912px;left:821px;white-space:nowrap" class="ft34">&#160;</p>
<p style="position:absolute;top:929px;left:459px;white-space:nowrap" class="ft34">4.5&#160;</p>
<p style="position:absolute;top:928px;left:479px;white-space:nowrap" class="ft34">×&#160;108&#160;unique ways to arrange 12 voxels to form a robot, and&#160;</p>
<p style="position:absolute;top:945px;left:459px;white-space:nowrap" class="ft39">the design space (the number of possible designs) increases&#160;<br/>exponentially&#160;with&#160;each&#160;additional&#160;block.[63]&#160;As a&#160;result, evo-<br/>lutionary[64–67]&#160;and learning[68,69]&#160;algorithms&#160;are usually&#160;<br/>employed to efficiently&#160;explore the vast space of possible&#160;robot&#160;&#160;<br/>designs.[70]</p>
<p style="position:absolute;top:1028px;left:474px;white-space:nowrap" class="ft34">Directly&#160;incorporating&#160;biologically&#160;inspired&#160;mechanisms&#160;of&#160;</p>
<p style="position:absolute;top:1044px;left:459px;white-space:nowrap" class="ft39">shape change—for example, slowly extruding limbs during&#160;<br/>optimization rather than optimizing controllers only for the&#160;</p>
<p style="position:absolute;top:342px;left:77px;white-space:nowrap" class="ft33"><b>Figure</b>&#160;<b>1.&#160;&#160;</b>Next-generation shape changing soft robots will sense their environment and adjust their shape and behavior to accommodate&#160;environmental&#160;</p>
<p style="position:absolute;top:356px;left:77px;white-space:nowrap" class="ft36">or terrain changes.</p>
<p style="position:absolute;top:1112px;left:77px;white-space:nowrap" class="ft37"><i>Adv.</i>&#160;<i>Mater.</i>&#160;<b>2020</b>, 2002882</p>
</div>
</body>
</html>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
<title>c01e2e7a02cda03fa7acf91fcfdbb4ca-html.html</title>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
 <br/>
<style type="text/css">
<!--
	p {margin: 0; padding: 0;}	.ft40{font-size:7px;font-family:Times;color:#231f20;}
	.ft41{font-size:8px;font-family:Times;color:#231f20;}
	.ft42{font-size:11px;font-family:Times;color:#231f20;}
	.ft43{font-size:10px;font-family:Times;color:#231f20;}
	.ft44{font-size:11px;font-family:Times;color:#231f20;}
	.ft45{font-size:15px;font-family:Times;color:#231f20;}
	.ft46{font-size:10px;font-family:Times;color:#231f20;}
	.ft47{font-size:6px;font-family:Times;color:#231f20;}
	.ft48{font-size:8px;font-family:Times;color:#231f20;}
	.ft49{font-size:8px;font-family:Times;color:#231f20;}
	.ft410{font-size:11px;line-height:16px;font-family:Times;color:#231f20;}
-->
</style>
</head>
<body bgcolor="#A0A0A0" vlink="blue" link="blue">
<div id="page4-div" style="position:relative;width:892px;height:1173px;">
<p style="position:absolute;top:1112px;left:701px;white-space:nowrap" class="ft40">©&#160;2020 Wiley-VCH GmbH</p>
<p style="position:absolute;top:1108px;left:395px;white-space:nowrap" class="ft42"><b>2002882&#160;&#160;(4 of 12)</b></p>
<p style="position:absolute;top:64px;left:739px;white-space:nowrap" class="ft43"><b>www.advmat.de</b></p>
<p style="position:absolute;top:64px;left:72px;white-space:nowrap" class="ft43"><b>www.advancedsciencenews.com</b></p>
<p style="position:absolute;top:648px;left:72px;white-space:nowrap" class="ft410">final, legged form of the robot—has been shown to speed the&#160;<br/>evolution of robust, adaptive behavior in simulated robots.[71]&#160;<br/>In other cases, evolved robots have rediscovered natural strat-<br/>egies&#160;on&#160;their&#160;own.&#160;For&#160;example,&#160;simulated soft&#160;robots&#160;evolved&#160;<br/>control policies that allowed them to squeeze their bodies&#160;<br/>through small apertures.[72]&#160;In another study, a simulated&#160;<br/>quadruped had all four of its legs simultaneously amputated;&#160;<br/>subsequently, evolution discovered that specific deformation&#160;<br/>to the resting shape could recover the robot’s function more&#160;<br/>effectively than re-adapting its control policy for its new body&#160;<br/>(<b>Figure</b> &#160;<b>2</b>),[31]&#160;which is analogous to biological regeneration,&#160;<br/>although using different mechanisms (mechanical deforma-<br/>tion versus regrowth).</p>
<p style="position:absolute;top:863px;left:87px;white-space:nowrap" class="ft44">Computational design can also discover novel ideas not&#160;</p>
<p style="position:absolute;top:879px;left:72px;white-space:nowrap" class="ft410">known to occur in nature. For example, regeneration was not&#160;<br/>the only successful adaptation strategy discovered by evolu-<br/>tion&#160;in&#160;the&#160;experiments&#160;reported&#160;by&#160;Kriegman&#160;et &#160;al.[31]&#160;When&#160;<br/>the simulated robot was cut in half, evolution sometimes&#160;<br/>decreased the damaged robot’s surface area by compressing the&#160;<br/>remaining&#160;limbs,&#160;and&#160;other&#160;times&#160;it&#160;expanded&#160;the&#160;robot’s&#160;limbs,&#160;<br/>compressed its spine, and flipped over to recover an inverted&#160;<br/>locomotion&#160;strategy.&#160;Within&#160;and&#160;across&#160;nine&#160;different&#160;damage&#160;<br/>scenarios, the best shape-shifting strategies were diverse and&#160;<br/>creative:&#160;very&#160;few&#160;were&#160;a&#160;recapitulation&#160;of&#160;a&#160;familiar&#160;biological&#160;<br/>example. Thus, simulation can provide non-intuitive designs&#160;<br/>beyond those inspired by natural systems.</p>
<p style="position:absolute;top:103px;left:455px;white-space:nowrap" class="ft45"><b>4. Shape Changing Robots</b></p>
<p style="position:absolute;top:137px;left:455px;white-space:nowrap" class="ft410">While biological and simulated systems alike indicate that&#160;<br/>even small shape adaptations can enable recovered or new&#160;<br/>functionalities, realizing shape changing robots in hardware&#160;<br/>presents&#160;its&#160;own&#160;set&#160;of&#160;unique&#160;challenges.&#160;However,&#160;we&#160;see&#160;<br/>immense potential in the convergence of multifunctional mate-<br/>rials and soft robotics toward the goal of shape changing robots,&#160;<br/>and some promising examples already exist. Here, we focus&#160;<br/>on&#160;examples&#160;of&#160;physical&#160;robots&#160;that&#160;employ&#160;shape&#160;change&#160;to&#160;<br/>enhance, recover, or expand their capabilities.</p>
<p style="position:absolute;top:285px;left:470px;white-space:nowrap" class="ft44">Several robots have leveraged functional materials to change&#160;</p>
<p style="position:absolute;top:302px;left:455px;white-space:nowrap" class="ft410">shape, to attain new gaits, and avoid obstacles, thereby solving&#160;<br/>problems that are traditionally in the realm of mechanics[73]&#160;<br/>and computer science.[74]&#160;For example, Shah et &#160;al. proposed a&#160;<br/>rolling soft robot that uses a cable-driven robotic skin to sculpt&#160;<br/>an inner clay body into a different morphology (<b>Figure</b> &#160;<b>3</b>a).[30]&#160;<br/>Initially cylindrical, the robot could roll on flat ground; when&#160;<br/>it encountered an obstacle in its path, the robot changed into&#160;<br/>a dumbbell shape to roll over the obstacle without changing its&#160;<br/>gait or path. While the robot was designed with 20 independent&#160;<br/>degrees of freedom (DoFs) for shape changing, it was found&#160;<br/>that only a single DoF was necessary to perform the required&#160;<br/>obstacle avoidance. In another example, a caterpillar-inspired&#160;<br/>robot called GoQBot changed its shape to switch between con-<br/>trolled&#160;crawling and ballistic&#160;rolling&#160;gaits (Figure 3c).[75]&#160;Using&#160;<br/>shape memory alloy (SMA) coils to deform its silicone body in&#160;<br/>small arches, the robot could crawl forward. Upon rapid activa-<br/>tion of the SMA actuators, the robot curled into a ball shape&#160;<br/>and initiated rolling in under 250 ms. Such a maneuver could&#160;<br/>be useful for&#160;escaping predation,&#160;rolling downhill in&#160;an energy-<br/>efficient manner, and increasing the robot’s effective dimen-<br/>sions to enable it to easily overcome obstacles larger than its&#160;<br/>flattened shape. In yet another example, Lee et &#160;al. proposed a&#160;<br/>robot that folds fabric and sheets of poly(ethylene terephthalate)&#160;<br/>(PET) to enlarge its wheels and climb onto step-like platforms&#160;<br/>(Figure &#160;3d).[28]&#160;The robot was then able to collapse its wheels&#160;<br/>to roll under narrow gaps, allowing the robot to operate over a&#160;<br/>wide range of terrains and environmental conditions. Despite&#160;<br/>being primarily made of flexible materials, the robot was able to&#160;<br/>use cleverly designed folding patterns to support a payload 400</p>
<p style="position:absolute;top:763px;left:809px;white-space:nowrap" class="ft44">×&#160;</p>
<p style="position:absolute;top:780px;left:455px;white-space:nowrap" class="ft410">the weight of its wheels. To adapt to changing flow conditions&#160;<br/>underwater, Ishida et &#160;al. developed a quadruped with a 4-DoF&#160;<br/>morphing top that could change its drag and lift coefficients to&#160;<br/>gain assistance from the current when the flow aligned with its&#160;<br/>direction of motion, and reduce drag when walking against the&#160;<br/>flow.[76]&#160;Similar to the rest of the robots in this category, only a&#160;<br/>few&#160;DoF for&#160;shape&#160;change&#160;were required&#160;to&#160;allow&#160;these&#160;robots&#160;<br/>to&#160;continue&#160;operation,&#160;without&#160;searching&#160;for&#160;complex&#160;control&#160;<br/>strategies to deal with changes in its environment.</p>
<p style="position:absolute;top:929px;left:470px;white-space:nowrap" class="ft44">Other&#160;soft&#160;robots&#160;have&#160;used&#160;shape&#160;change&#160;to&#160;switch&#160;between&#160;</p>
<p style="position:absolute;top:945px;left:455px;white-space:nowrap" class="ft410">locomotion on land, in air, and/or in water. Baines et &#160;al.&#160;<br/>recently demonstrated a life-size turtle- and tortoise-inspired&#160;<br/>morphing limb that could change between flipper and leg&#160;<br/>shapes, as a step toward amphibious robots which can accom-<br/>plish both aquatic and terrestrial locomotion (Figure &#160;3f).[77,78]&#160;<br/>The transformation from flipper to leg occurred via coupled&#160;<br/>variable stiffness and actuation materials distributed along the&#160;<br/>length of the morphing limb. Initially in a flipper shape, fluidic&#160;</p>
<p style="position:absolute;top:552px;left:72px;white-space:nowrap" class="ft43"><b>Figure</b>&#160;<b>2.&#160;&#160;</b>Simulations&#160;can&#160;automatically&#160;generate&#160;complex&#160;shape&#160;changing&#160;</p>
<p style="position:absolute;top:566px;left:72px;white-space:nowrap" class="ft46">robots, including ones that recover from damage through shape change.&#160;</p>
<p style="position:absolute;top:580px;left:72px;white-space:nowrap" class="ft46">The quadrupedal robot shown here discovered that, after being damaged,&#160;</p>
<p style="position:absolute;top:594px;left:72px;white-space:nowrap" class="ft46">it was more advantageous to change its shape than adapt its control&#160;</p>
<p style="position:absolute;top:609px;left:72px;white-space:nowrap" class="ft46">policy. Adapted with permission.[31]&#160;Copyright 2019, Sam Kriegman.</p>
<p style="position:absolute;top:1112px;left:72px;white-space:nowrap" class="ft48"><i>Adv.</i>&#160;<i>Mater.</i>&#160;<b>2020</b>, 2002882</p>
</div>
</body>
</html>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
<title>c01e2e7a02cda03fa7acf91fcfdbb4ca-html.html</title>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
 <br/>
<style type="text/css">
<!--
	p {margin: 0; padding: 0;}	.ft50{font-size:7px;font-family:Times;color:#231f20;}
	.ft51{font-size:8px;font-family:Times;color:#231f20;}
	.ft52{font-size:11px;font-family:Times;color:#231f20;}
	.ft53{font-size:10px;font-family:Times;color:#231f20;}
	.ft54{font-size:11px;font-family:Times;color:#231f20;}
	.ft55{font-size:10px;font-family:Times;color:#231f20;}
	.ft56{font-size:6px;font-family:Times;color:#231f20;}
	.ft57{font-size:8px;font-family:Times;color:#231f20;}
	.ft58{font-size:8px;font-family:Times;color:#231f20;}
	.ft59{font-size:11px;line-height:16px;font-family:Times;color:#231f20;}
-->
</style>
</head>
<body bgcolor="#A0A0A0" vlink="blue" link="blue">
<div id="page5-div" style="position:relative;width:892px;height:1173px;">
<p style="position:absolute;top:1112px;left:704px;white-space:nowrap" class="ft50">©&#160;2020 Wiley-VCH GmbH</p>
<p style="position:absolute;top:1108px;left:399px;white-space:nowrap" class="ft52"><b>2002882&#160;&#160;(5 of 12)</b></p>
<p style="position:absolute;top:64px;left:743px;white-space:nowrap" class="ft53"><b>www.advmat.de</b></p>
<p style="position:absolute;top:64px;left:77px;white-space:nowrap" class="ft53"><b>www.advancedsciencenews.com</b></p>
<p style="position:absolute;top:104px;left:77px;white-space:nowrap" class="ft59">actuators inflated, causing a change in limb cross-sectional&#160;<br/>geometry&#160;to&#160;transition&#160;to&#160;the&#160;load-bearing leg&#160;shape.&#160;The&#160;vari-<br/>able stiffness material, a thermoset polymer with embedded&#160;<br/>heaters, controllably softened and stiffened the limb to lock&#160;<br/>and unlock the geometries. Hawkes et &#160;al. designed an ori-<br/>gami robot that could fold between shapes resembling a boat&#160;</p>
<p style="position:absolute;top:104px;left:459px;white-space:nowrap" class="ft59">and a plane (Figure &#160;3e).[79]&#160;Although these structures were&#160;<br/>not demonstrated moving through air or water, locomotion&#160;<br/>could&#160;potentially&#160;be&#160;achieved&#160;through&#160;integration of additional&#160;<br/>actuators. For example, other lightweight origami robots[80]&#160;<br/>attained controlled flight resembling the locomotion paths of&#160;<br/>insects.[81,82]</p>
<p style="position:absolute;top:977px;left:77px;white-space:nowrap" class="ft53"><b>Figure</b>&#160;<b>3.&#160;&#160;</b>Shape changing soft robots. a) Cable-driven clay morphing robot changing shape to avoid an obstacle. Adapted with permission.[30]&#160;Copyright&#160;</p>
<p style="position:absolute;top:991px;left:77px;white-space:nowrap" class="ft55">2019, IEEE.&#160;b) Cylindrical&#160;rolling robot&#160;flattens to switch&#160;from a rolling&#160;gait to&#160;a crawling&#160;gait.&#160;Reproduced with&#160;permission.[87]&#160;Copyright&#160;2020, The&#160;</p>
<p style="position:absolute;top:1005px;left:77px;white-space:nowrap" class="ft55">Authors. c) Caterpillar robot changing from inching to rolling. Adapted with permission.[75]&#160;Copyright 2011, IOP Publishing. d) Variable diameter origami&#160;</p>
<p style="position:absolute;top:1020px;left:77px;white-space:nowrap" class="ft55">wheel. Adapted with permission.[28]&#160;Copyright 2017, Mary Ann Liebert, Inc. e) Programmable origami robot transitioning between a “boat” and a “plane”&#160;</p>
<p style="position:absolute;top:1034px;left:77px;white-space:nowrap" class="ft55">shape. Adapted with permission.[79]&#160;Copyright 2010, National Academy of Sciences. f) Variable stiffness morphing limb for an amphibious legged robot.&#160;</p>
<p style="position:absolute;top:1048px;left:77px;white-space:nowrap" class="ft55">Adapted with permission.[78]&#160;Copyright 2020, IOP Publishing. g) Magnetically actuated soft capsule for drug delivery. Adapted with permission.[26]&#160;</p>
<p style="position:absolute;top:1062px;left:77px;white-space:nowrap" class="ft55">Copyright 2012, IEEE. h) Tissue engineered robot with light-activated morphing wings. Reproduced with permission.[83]&#160;Copyright 2019, Wiley-VCH.</p>
<p style="position:absolute;top:1112px;left:77px;white-space:nowrap" class="ft57"><i>Adv.</i>&#160;<i>Mater.</i>&#160;<b>2020</b>, 2002882</p>
</div>
</body>
</html>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
<title>c01e2e7a02cda03fa7acf91fcfdbb4ca-html.html</title>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
 <br/>
<style type="text/css">
<!--
	p {margin: 0; padding: 0;}	.ft60{font-size:7px;font-family:Times;color:#231f20;}
	.ft61{font-size:8px;font-family:Times;color:#231f20;}
	.ft62{font-size:11px;font-family:Times;color:#231f20;}
	.ft63{font-size:10px;font-family:Times;color:#231f20;}
	.ft64{font-size:11px;font-family:Times;color:#231f20;}
	.ft65{font-size:15px;font-family:Times;color:#231f20;}
	.ft66{font-size:10px;font-family:Times;color:#231f20;}
	.ft67{font-size:6px;font-family:Times;color:#231f20;}
	.ft68{font-size:8px;font-family:Times;color:#231f20;}
	.ft69{font-size:8px;font-family:Times;color:#231f20;}
	.ft610{font-size:11px;line-height:16px;font-family:Times;color:#231f20;}
	.ft611{font-size:15px;line-height:30px;font-family:Times;color:#231f20;}
-->
</style>
</head>
<body bgcolor="#A0A0A0" vlink="blue" link="blue">
<div id="page6-div" style="position:relative;width:892px;height:1173px;">
<p style="position:absolute;top:1112px;left:701px;white-space:nowrap" class="ft60">©&#160;2020 Wiley-VCH GmbH</p>
<p style="position:absolute;top:1108px;left:395px;white-space:nowrap" class="ft62"><b>2002882&#160;&#160;(6 of 12)</b></p>
<p style="position:absolute;top:64px;left:739px;white-space:nowrap" class="ft63"><b>www.advmat.de</b></p>
<p style="position:absolute;top:64px;left:72px;white-space:nowrap" class="ft63"><b>www.advancedsciencenews.com</b></p>
<p style="position:absolute;top:351px;left:87px;white-space:nowrap" class="ft64">Shape change has also been used in human-centered appli-</p>
<p style="position:absolute;top:368px;left:72px;white-space:nowrap" class="ft610">cations. Yim and Sitti proposed a millimeter-scale, magneti-<br/>cally actuated capsule that can locomote and switch between&#160;a&#160;<br/>spherical&#160;and&#160;cylindrical&#160;shape&#160;(Figure &#160;3g).[26,27]&#160;Although&#160;the&#160;<br/>robot could locomote in each shape, the robot used shape change&#160;<br/>to improve the precise positioning of its endpoints, and deliver&#160;<br/>simulated drugs inside of a synthetic stomach model. Another&#160;<br/>proposed millimeter-scale robot had oscillating cardiac muscle&#160;<br/>cells attached to the back of airplane-shaped “wings” to propel it&#160;<br/>across the surface of the liquid medium in a cell culture, simu-<br/>lating applications in targeted drug delivery in the human body&#160;<br/>(Figure &#160;3h).[83]&#160;When the “wings” absorbed near-infrared radia-<br/>tion, heat spread to their attached temperature-sensitive hydrogel&#160;<br/>actuators to induce curling. The curled shape had a higher&#160;<br/>bending stiffness that prevented further swimming motions,&#160;<br/>allowing the robot to stop directly above a target location and&#160;<br/>release anticancer drugs onto cancer cells. Finally, researchers&#160;<br/>have demonstrated that shape change can alter our perception of&#160;<br/>robots during&#160;human–robot&#160;interactions,[84–86]&#160;thereby&#160;improving&#160;<br/>these exchanges and increasing the operational value of the robot.</p>
<p style="position:absolute;top:681px;left:87px;white-space:nowrap" class="ft64">Researchers have also explored the potential for auto-</p>
<p style="position:absolute;top:698px;left:72px;white-space:nowrap" class="ft610">matically designing shape changing robots in simulation&#160;<br/>and transferring successful designs to reality. Kriegman et &#160;al.&#160;<br/>developed a scalable method to create physical shape changing&#160;<br/>voxel-based modular robots, and successfully transferred two&#160;<br/>strategies of shape change discovered in simulation to reality;&#160;<br/>however, functionality (locomotion) did not transfer.[31]&#160;Later,&#160;<br/>locomotion was transferred from simulation to reality using&#160;<br/>an improved version of the same system (silicone-based pneu-<br/>matic voxels), however these locomoting physical robots did not&#160;<br/>change shape.[43]&#160;Another simulated shape changing robot used&#160;<br/>an inflatable core to transition between a cylindrical shape and&#160;<br/>a flattened sheet-like shape to adapt its locomotion to different&#160;<br/>environments.[87]&#160;Initially a rolling cylinder on flat terrain, the&#160;<br/>robot changed to the flattened shape with an inchworm gait&#160;<br/>to maintain efficient locomotion up an incline. This simulated&#160;<br/>robot design was successfully transferred to reality, thereby real-<br/>izing a physical robot that utilizes shape change to gain access&#160;<br/>to additional environments (Figure 3b).</p>
<p style="position:absolute;top:1030px;left:72px;white-space:nowrap" class="ft610"><b>5. Grand Challenges<br/></b>The examples given herein highlight how shape change&#160;<br/>can allow a robot to enhance or expand its functionality via&#160;</p>
<p style="position:absolute;top:351px;left:455px;white-space:nowrap" class="ft610">adaptation or regeneration. However, to develop robots rivaling&#160;<br/>biological systems, several challenges&#160;need to be addressed.&#160;<br/>First, it is unclear how to optimally embed proprioception and&#160;<br/>intelligence into such machines to enable robots to sense their&#160;<br/>shape.&#160;Additionally,&#160;to design&#160;robots&#160;for tasks&#160;more&#160;complicated&#160;<br/>than can be solved through human intuition, it is imperative to&#160;<br/>automate the design of shape changing robots. Finally, trans-<br/>ferring&#160;highly&#160;functional&#160;designs&#160;to&#160;reality&#160;requires&#160;functional&#160;<br/>materials that can be integrated into systems that can attain&#160;<br/>precise control over shape.</p>
<p style="position:absolute;top:549px;left:455px;white-space:nowrap" class="ft62"><b>5.1. Shape Sensing</b></p>
<p style="position:absolute;top:582px;left:455px;white-space:nowrap" class="ft610">Next-generation shape changing robots will rely on propriocep-<br/>tion to determine when a target morphology has been reached,&#160;<br/>optimize shape change through intermediate shapes, and&#160;<br/>decouple deformation-driven task performance from global&#160;<br/>shape change. During regeneration, an organisms’ cells compare&#160;<br/>their&#160;body’s&#160;current&#160;state&#160;to&#160;the&#160;target&#160;morphology,&#160;although&#160;the&#160;<br/>exact mechanisms for these processes are poorly understood.[4]&#160;<br/>Techniques exist for measuring the deformation of fixed-shape&#160;<br/>robots, which generally rely on a comparison to the reference&#160;<br/>body shape at rest. For example, continuum manipulator mod-<br/>eling relies upon assumptions about cross-sectional geometry,[88]&#160;<br/>while traditional robot kinematics assume each component is a&#160;<br/>rigid body.[89]&#160;However,&#160;if the reference&#160;body shape&#160;is changing,&#160;<br/>such an approach is no longer applicable. Thus, intrinsically&#160;<br/>(i.e., without external components) measuring the state of shape&#160;<br/>changing robots largely remains an unsolved problem.[90]</p>
<p style="position:absolute;top:846px;left:470px;white-space:nowrap" class="ft64">There have been several attempts to detect the shape of non-</p>
<p style="position:absolute;top:863px;left:455px;white-space:nowrap" class="ft610">stretchable robot “skins” (<b>Figure</b> <b>4</b>). Many studies treat the skin&#160;<br/>as an inextensible sheet of rigid elements joined by known&#160;<br/>axes of rotation (Figure &#160;4, left). Hoshi and Shinoda arranged&#160;&#160;<br/>24 printed circuit boards (PCBs) into a mesh and estimated&#160;<br/>inter-PCB rotations using accelerometers and magnetometers.[39]&#160;<br/>Building upon this work, Mittendorfer et &#160;al. developed rigid&#160;<br/>sensorized PCBs that could be connected and wrapped around&#160;<br/>robots.[40]&#160;Hermanis et al. then used a grid-like arrangement of&#160;<br/>accelerometers&#160;and&#160;gravitometers&#160;on&#160;a&#160;flexible&#160;fabric&#160;sheet.[37]&#160;<br/>In these studies, no attempt was made to estimate the true&#160;<br/>shape of the underlying object; the objective was to measure&#160;<br/>the location of the PCBs’ centers with high precision.</p>
<p style="position:absolute;top:1061px;left:470px;white-space:nowrap" class="ft64">Other proposed approaches leveraged techniques from&#160;</p>
<p style="position:absolute;top:1077px;left:455px;white-space:nowrap" class="ft64">machine learning and statistics to process sensor signals and&#160;</p>
<p style="position:absolute;top:254px;left:72px;white-space:nowrap" class="ft63"><b>Figure</b>&#160;&#160;<b>4.&#160;&#160;</b>Sheets that can sense their 3D shape. Recent advances in shape-sensing e-skins use several sensing modalities, ranging from&#160;discrete&#160;</p>
<p style="position:absolute;top:269px;left:72px;white-space:nowrap" class="ft66">to continuous approaches. Left to right: hexagonal PCBs with integrated accelerometers, sensor network with accelerometers and&#160;magnetometers,&#160;</p>
<p style="position:absolute;top:283px;left:72px;white-space:nowrap" class="ft66">optical fibers in silicone foam, fiber Bragg gratings in silicone. Image for Hexagonal PCBs: Adapted with permission.[40]&#160;Copyright 2012, IEEE. Image for&#160;</p>
<p style="position:absolute;top:297px;left:72px;white-space:nowrap" class="ft66">sensor network: Reproduced with permission.[37]&#160;Copyright 2012, IEEE. Image for opical fiber: Adapted with permission.[91]&#160;Copyright 2018, The Authors,&#160;</p>
<p style="position:absolute;top:311px;left:72px;white-space:nowrap" class="ft66">published by American Association for the Advancement of Science. Image for fiber Bragg grating: Adapted with permission.[41]&#160;Copyright 2019, IEEE.</p>
<p style="position:absolute;top:1112px;left:72px;white-space:nowrap" class="ft68"><i>Adv.</i>&#160;<i>Mater.</i>&#160;<b>2020</b>, 2002882</p>
</div>
</body>
</html>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
<title>c01e2e7a02cda03fa7acf91fcfdbb4ca-html.html</title>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
 <br/>
<style type="text/css">
<!--
	p {margin: 0; padding: 0;}	.ft70{font-size:7px;font-family:Times;color:#231f20;}
	.ft71{font-size:8px;font-family:Times;color:#231f20;}
	.ft72{font-size:11px;font-family:Times;color:#231f20;}
	.ft73{font-size:10px;font-family:Times;color:#231f20;}
	.ft74{font-size:11px;font-family:Times;color:#231f20;}
	.ft75{font-size:8px;font-family:Times;color:#231f20;}
	.ft76{font-size:8px;font-family:Times;color:#231f20;}
	.ft77{font-size:11px;line-height:16px;font-family:Times;color:#231f20;}
-->
</style>
</head>
<body bgcolor="#A0A0A0" vlink="blue" link="blue">
<div id="page7-div" style="position:relative;width:892px;height:1173px;">
<p style="position:absolute;top:1112px;left:704px;white-space:nowrap" class="ft70">©&#160;2020 Wiley-VCH GmbH</p>
<p style="position:absolute;top:1108px;left:400px;white-space:nowrap" class="ft72"><b>2002882&#160;&#160;(7 of 12)</b></p>
<p style="position:absolute;top:64px;left:743px;white-space:nowrap" class="ft73"><b>www.advmat.de</b></p>
<p style="position:absolute;top:64px;left:77px;white-space:nowrap" class="ft73"><b>www.advancedsciencenews.com</b></p>
<p style="position:absolute;top:104px;left:77px;white-space:nowrap" class="ft77">extract a continuous estimate of the shape of the skins (Figure 4,&#160;<br/>right). Such an approach is more general, and could potentially&#160;<br/>lead to more accurate estimations of the state of shape changing&#160;<br/>soft robots. Rendl et &#160;al. used data from 16 piezoelectric bend&#160;<br/>sensors, which experience a potential difference on their elec-<br/>trodes during bending, on a PET sheet to estimate the sheet’s&#160;<br/>shape as a combination of several shape primitives.[38]&#160;Another&#160;<br/>study used neural networks to estimate the shape of a silicone&#160;<br/>plate&#160;using inextensible optical fiber&#160;Bragg gratings strain sen-<br/>sors (coated with ORMOCER inorganic–organic hybrid poly-<br/>mers).[41]&#160;Van Meerbeek et &#160;al. embedded an array of optical&#160;<br/>fibers inside an open-celled elastomeric foam and used their&#160;<br/>output to predict the mode of deformation and angle of defor-<br/>mation of the foam, using machine learning algorithms.[91]</p>
<p style="position:absolute;top:335px;left:92px;white-space:nowrap" class="ft74">Several challenges emerge from inspection of these works.&#160;</p>
<p style="position:absolute;top:351px;left:77px;white-space:nowrap" class="ft77">Some shortcomings arise from material limitations: none of&#160;<br/>the proposed approaches could accommodate or detect in-plane&#160;<br/>strains. There are solutions to making stretchable strain sen-<br/>sors[92–94]&#160;and stretchable circuits,[95,96]&#160;but is is unclear how to&#160;<br/>transfer these advances to sense a variety of dissimilar shapes.&#160;<br/>For&#160;instance,&#160;how&#160;many&#160;sensors,&#160;and&#160;what&#160;type&#160;of&#160;sensors,&#160;are&#160;<br/>needed to detect the shape of each robot in Figure 3? Biological&#160;<br/>organisms, such as humans, distribute multimodal sensing&#160;<br/>capabilities across their skin and at multiple depths,[97]&#160;and&#160;<br/>throughout their musculoskeletal system.[98]&#160;The efficiency of&#160;<br/>this approach is unclear, as evolution selects for survival, and&#160;<br/>biological constraints do not map perfectly to the constraints&#160;<br/>and cost–benefit relationships relevant in robotics. Additionally,&#160;<br/>how can sensors be developed to decouple large in-plane strains&#160;<br/>from transverse strain (pressure), at sufficiently high resolu-<br/>tion? Some&#160;progress has&#160;been made toward&#160;independent multi-<br/>modal sensing for robots with a fixed resting&#160;shape,[99]&#160;but&#160;these&#160;<br/>methods have yet to be tested in shape changing robots. Finally,&#160;<br/>the proprioceptive sensors used in shape changing robots should&#160;<br/>be simultaneously robust to repeated applications of external&#160;<br/>strain, able to withstand undesired local shear forces, and easy&#160;<br/>to manufacture at the densities needed to detect the complicated&#160;<br/>deformations experienced during typical operations.</p>
<p style="position:absolute;top:731px;left:92px;white-space:nowrap" class="ft74">Other challenges are algorithmic: each proposed sensing&#160;</p>
<p style="position:absolute;top:747px;left:77px;white-space:nowrap" class="ft77">approach—broadly, what we classify as discrete versus contin-<br/>uous&#160;approaches—has&#160;drawbacks. The discrete&#160;method insuf-<br/>ficiently handles continuously deformable surfaces, while the&#160;<br/>data-driven&#160;continuous&#160;approach&#160;only operates&#160;under limited&#160;<br/>deformation conditions. Solutions in this regard could involve&#160;<br/>applying techniques from differential geometry to fuse rotation&#160;<br/>and strain data to generate smooth surface estimates.[100–103]&#160;In&#160;<br/>the work by Stanko et &#160;al.,[100]&#160;a single algorithm was used to&#160;<br/>estimate&#160;the&#160;shape&#160;of&#160;objects&#160;as&#160;dissimilar&#160;as&#160;a&#160;mushroom,&#160;a&#160;<br/>chair, and a guitar. The only required input was distance esti-<br/>mates between successive orientation measurements. When&#160;<br/>paired with stretchable strain sensors[92–94]&#160;and stretchable&#160;<br/>circuits,[95,96]&#160;such algorithms could provide solutions to the&#160;<br/>overall problem of estimating the shape of a morphing robot.</p>
<p style="position:absolute;top:1011px;left:77px;white-space:nowrap" class="ft72"><b>5.2. Shape Finding</b></p>
<p style="position:absolute;top:1044px;left:77px;white-space:nowrap" class="ft77">It is not obvious which shape a robot should assume in a given&#160;<br/>environment. While evolutionary robotics[35]&#160;may yield potential&#160;&#160;</p>
<p style="position:absolute;top:104px;left:459px;white-space:nowrap" class="ft77">solutions, there are many unresolved fundamental questions&#160;<br/>in this area. For example: How will a robot know that its cur-<br/>rent shape is no longer optimal, and it should search for a new&#160;<br/>shape and behavioral policy? How should robot shapes and&#160;<br/>behaviors be generated given only environmental inputs? Here,&#160;<br/>we explore how the state-of-the-art could be improved to create&#160;<br/>automated pipelines for finding effective shapes and designing&#160;<br/>sophisticated shape changing robots.</p>
<p style="position:absolute;top:236px;left:474px;white-space:nowrap" class="ft74">The application of evolutionary algorithms to simulated&#160;</p>
<p style="position:absolute;top:252px;left:459px;white-space:nowrap" class="ft77">robots has begun to address the questions above,&#160;but only&#160;<br/>within empirical studies with one or two objectives for the&#160;<br/>robots to solve.[31,87,104]&#160;Further, higher-level and/or trans-<br/>environmental tasks have been largely unexplored. Although&#160;<br/>evolved&#160;simulated robots&#160;have&#160;transitioned&#160;between terrestrial&#160;<br/>and aqueous environments,[64]&#160;no general understanding&#160;of&#160;<br/>how shape change can equip a machine to travel through air,&#160;<br/>water, or over land yet exists. Transitioning between shapes to&#160;<br/>solve widely varied tasks such as locomotion&#160;and grasping&#160;has&#160;<br/>not been considered, nor has changing shape in real time to&#160;<br/>avoid damage. To address these scenarios, the major challenges&#160;<br/>of catastrophic forgetting,[105]&#160;transferability,[106,107]&#160;simulation&#160;<br/>inaccuracies,&#160;system&#160;identification,[65]&#160;and&#160;the limited&#160;effi-<br/>ciency and sub-optimality of search algorithms likely need to&#160;<br/>be considered.</p>
<p style="position:absolute;top:500px;left:474px;white-space:nowrap" class="ft74">Most existing studies on simulated morphing ignored the&#160;</p>
<p style="position:absolute;top:516px;left:459px;white-space:nowrap" class="ft77">costs of shape change. Although shape change is sometimes&#160;<br/>more computationally efficient than searching for control poli-<br/>cies,[31,87]&#160;in&#160;hardware&#160;implementations,&#160;there&#160;is&#160;an&#160;energetic&#160;<br/>cost associated with changing shape. Energy must be expended&#160;<br/>to power actuators (e.g., SMAs and shape memory poly-<br/>mers,[108,109]&#160;dielectric elastomer actuators,[110]&#160;or various other&#160;<br/>soft actuators[111]) and materials may need to be replaced during&#160;<br/>regeneration or growth (e.g., via inflation,[31,112]&#160;additive manu-<br/>facture,[113]&#160;etc.). Quantifying both the computational and ener-<br/>getic costs of shape change will be important to the realization&#160;<br/>of shape changing robots that operate in the real world.</p>
<p style="position:absolute;top:698px;left:474px;white-space:nowrap" class="ft74">Additionally, it is challenging to specify algorithmic con-</p>
<p style="position:absolute;top:714px;left:459px;white-space:nowrap" class="ft77">straints that guarantee that the shape and behavior solutions&#160;<br/>found are physically realizable. While it is possible to stretch&#160;<br/>any two homeomorphic shapes into each other, generating&#160;<br/>designs which are robust to simulator inaccuracies requires&#160;<br/>sufficiently&#160;realistic&#160;constraints,&#160;and&#160;algorithms&#160;that&#160;can&#160;navi-<br/>gate&#160;a&#160;constrained,&#160;likely&#160;highly&#160;non-convex,&#160;search&#160;space.&#160;<br/>Numerous&#160;methods to&#160;navigate&#160;the simulation–reality&#160;gap&#160;<br/>have been proposed, including injecting noise into the simula-<br/>tions[106]&#160;and estimating an assumed transferability function.[107]&#160;<br/>Other approaches for crossing the simulation–reality gap in soft&#160;<br/>robotics&#160;include&#160;reducing&#160;the&#160;robot to&#160;quasi-static&#160;motions[60]&#160;<br/>and simplifying the search space.[104]&#160;However, these simplifica-<br/>tions dramatically reduce the range of capabilities that can be&#160;<br/>evolved and limit the scope of tasks that can be completed.</p>
<p style="position:absolute;top:978px;left:459px;white-space:nowrap" class="ft72"><b>5.3. Shape Changing</b></p>
<p style="position:absolute;top:1011px;left:459px;white-space:nowrap" class="ft77">Most morphing robots in the literature have been designed to&#160;<br/>attain a limited set of shapes as a proof-of-concept. Increasing&#160;<br/>the controllable degrees of freedom should generally improve&#160;<br/>the shape changing abilities of robots (<b>Figure</b> &#160;<b>5</b>), but such&#160;</p>
<p style="position:absolute;top:1112px;left:77px;white-space:nowrap" class="ft75"><i>Adv.</i>&#160;<i>Mater.</i>&#160;<b>2020</b>, 2002882</p>
</div>
</body>
</html>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
<title>c01e2e7a02cda03fa7acf91fcfdbb4ca-html.html</title>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
 <br/>
<style type="text/css">
<!--
	p {margin: 0; padding: 0;}	.ft80{font-size:7px;font-family:Times;color:#231f20;}
	.ft81{font-size:8px;font-family:Times;color:#231f20;}
	.ft82{font-size:11px;font-family:Times;color:#231f20;}
	.ft83{font-size:10px;font-family:Times;color:#231f20;}
	.ft84{font-size:11px;font-family:Times;color:#231f20;}
	.ft85{font-size:10px;font-family:Times;color:#231f20;}
	.ft86{font-size:6px;font-family:Times;color:#231f20;}
	.ft87{font-size:8px;font-family:Times;color:#231f20;}
	.ft88{font-size:8px;font-family:Times;color:#231f20;}
	.ft89{font-size:11px;line-height:16px;font-family:Times;color:#231f20;}
-->
</style>
</head>
<body bgcolor="#A0A0A0" vlink="blue" link="blue">
<div id="page8-div" style="position:relative;width:892px;height:1173px;">
<p style="position:absolute;top:1112px;left:701px;white-space:nowrap" class="ft80">©&#160;2020 Wiley-VCH GmbH</p>
<p style="position:absolute;top:1108px;left:395px;white-space:nowrap" class="ft82"><b>2002882&#160;&#160;(8 of 12)</b></p>
<p style="position:absolute;top:64px;left:739px;white-space:nowrap" class="ft83"><b>www.advmat.de</b></p>
<p style="position:absolute;top:64px;left:72px;white-space:nowrap" class="ft83"><b>www.advancedsciencenews.com</b></p>
<p style="position:absolute;top:401px;left:72px;white-space:nowrap" class="ft89">complexity comes with trade-offs and limitations. For example,&#160;<br/>origami&#160;robots[80]&#160;are typically&#160;designed&#160;to&#160;attain&#160;a limited&#160;set&#160;of&#160;<br/>shapes by folding at discrete locations (Figure 5, left).[28]&#160;Addi-<br/>tional shapes could be achieved by adding or utilizing additional&#160;<br/>folds, but would increase the system’s complexity. The clay-<br/>sculpting robotic skins[30]&#160;were designed to stretch with their&#160;<br/>surface to attain a continuous range of shapes; however, they&#160;<br/>were restricted to shapes with circular cross-sections (Figure 5,&#160;<br/>second from left). Adding additional cables to this design, more&#160;<br/>complicated&#160;profiles&#160;could&#160;be&#160;attained,&#160;but&#160;the&#160;robot&#160;could&#160;not&#160;<br/>attain, for example, a quadrupedal shape. The field needs fun-<br/>damentally new approaches to shape change, including novel&#160;<br/>actuators and growth mechanisms, paired with complementary&#160;<br/>technologies to control surface strain.</p>
<p style="position:absolute;top:632px;left:87px;white-space:nowrap" class="ft84">Typically, a robot’s components are optimally placed for its&#160;</p>
<p style="position:absolute;top:648px;left:72px;white-space:nowrap" class="ft89">morphology&#160;and&#160;target&#160;function.&#160;Yet,&#160;for&#160;a&#160;shape&#160;changing&#160;robot,&#160;<br/>optimal component placement will differ between morphologies.&#160;<br/>One&#160;solution&#160;to&#160;this&#160;problem&#160;is&#160;to&#160;increase&#160;the&#160;sensor&#160;and&#160;actu-<br/>ator component density throughout the robot to increase its con-<br/>trollable degrees of freedom. Potential ways to increase sensor&#160;<br/>and actuator density include multifunctional materials,[115–117]&#160;<br/>3D circuits,[95]&#160;skins with tightly integrated sensing and actua-<br/>tion,[118]&#160;and multimodal&#160;sensing&#160;arrays.[97]&#160;However,&#160;numerous&#160;<br/>issues arise when increasing component density, including&#160;<br/>cross-talk, data processing, and complicated wiring schemes.[90]&#160;<br/>Communication protocols for large numbers of sensors or actu-<br/>ators is another challenge. Pneumatic robots, for example, usu-<br/>ally require one three-state (inflate, hold, release) valve set per&#160;<br/>actuator. Although pneumatic multiplexing has been shown to&#160;<br/>independently control large arrays of actuators,[119]&#160;multiplexers&#160;<br/>often result in a lower attainable actuation frequency.</p>
<p style="position:absolute;top:912px;left:87px;white-space:nowrap" class="ft84">To further expand the range of shapes that morphing robots&#160;</p>
<p style="position:absolute;top:929px;left:72px;white-space:nowrap" class="ft89">can&#160;attain,&#160;additional&#160;actuation&#160;modes&#160;need to&#160;be introduced.&#160;<br/>Many shape changing robots utilize a single actuation mode,&#160;<br/>for example, tension,[30]&#160;volumetric expansion,[120]&#160;origami&#160;<br/>folding,[28]&#160;or bending.[83]&#160;In contrast, many shape changing&#160;<br/>organisms exploit multiple actuation modes. For example, the&#160;<br/>tentacles of cephalopods and many species’ tongues tightly&#160;<br/>integrate muscles with different orientations to achieve torsion,&#160;<br/>extension, and bending (Figure &#160;5, second from right).[121,122]&#160;<br/>Integration of multiple actuation modes has largely been&#160;<br/>unexplored in the context of shape changing robots, and is a&#160;</p>
<p style="position:absolute;top:401px;left:455px;white-space:nowrap" class="ft89">major unsolved&#160;challenge. Much can be&#160;learned from the field&#160;<br/>of microrobotics, where many robots have been built using&#160;<br/>stimuli-responsive polymers. Often these robots contain several&#160;<br/>actuation modes in addition to novel functionalities, such as&#160;<br/>camouflage.[123–126]&#160;Stimuli used in these micro-machines (mag-<br/>netic fields,[123,125]&#160;chemical vapor,[124]&#160;light,[123]&#160;and solvent[126])&#160;<br/>are usually less practical for larger-scale soft robots due to unfa-<br/>vorable strength-to-weight ratios at larger length scales. With&#160;<br/>additional&#160;advances&#160;in fundamental&#160;materials&#160;science, imple-<br/>mentation&#160;of stimuli-responsive&#160;polymers&#160;in large-scale&#160;robots&#160;<br/>may become viable.</p>
<p style="position:absolute;top:582px;left:470px;white-space:nowrap" class="ft84">Combining novel actuators, robot-simulators, and shape-</p>
<p style="position:absolute;top:599px;left:455px;white-space:nowrap" class="ft89">sensing technologies, robots could then utilize 3D “shape ser-<br/>voing,” or closed-loop control of shape, to converge on a desired&#160;<br/>shape. In a 2D shape servoing application, an external vision&#160;<br/>system was paired with a robot arm to deform materials into&#160;<br/>a&#160;desired&#160;shape.[127]&#160;Building&#160;upon&#160;such&#160;extrinsic&#160;methods of&#160;<br/>shape control, it is conceivable that there will be optimal ways to&#160;<br/>use a robot’s actuators to smoothly shift between desired shapes.&#160;<br/>Insight into how to efficiently change shape could come from&#160;<br/>observing how sculptors smoothly sculpt clay between many&#160;<br/>highly&#160;dissimilar&#160;shapes.[30]&#160;Formalizing&#160;intuition&#160;and&#160;observa-<br/>tion into computationally tractable shape-control loops could&#160;<br/>come from mechanics-based modeling and solving an inverse&#160;<br/>problem (i.e., calculating the required control sequence to attain&#160;<br/>a desired shape), or using data-driven reinforcement learning&#160;<br/>models to solve problems in an automated, closed-loop fashion.</p>
<p style="position:absolute;top:846px;left:470px;white-space:nowrap" class="ft84">As&#160;a&#160;robot&#160;undergoes&#160;large&#160;changes&#160;in&#160;shape,&#160;the&#160;surface&#160;</p>
<p style="position:absolute;top:863px;left:455px;white-space:nowrap" class="ft89">stress can often approach the maximum available actuator&#160;<br/>stress and restrict further motion. To overcome these limi-<br/>tations, one solution is to design robots that can reversibly&#160;<br/>undergo large deformations.[21,24]&#160;In contrast, many biological&#160;<br/>organisms experience large-scale, growth-driven shape change&#160;<br/>in response to numerous stimuli,[6,33]&#160;promoting long-term via-<br/>bility of the organism (Figure 5, right). It is hypothesized that&#160;<br/>control of these factors could eventually lead to synthetic organ-<br/>isms with programmable growth from varied initial states into&#160;<br/>target morphologies. Recent studies have proposed continuum&#160;<br/>robots that can grow along an arc-like path, using eversion[79]&#160;<br/>and tip-based&#160;additive manufacturing.[113]&#160;Progress&#160;is also being&#160;<br/>made in related fields, such as biohybrid robots,[128]&#160;expanding&#160;<br/>polymers[129]&#160;and hydrogels,[130]&#160;and simulating growing&#160;</p>
<p style="position:absolute;top:265px;left:72px;white-space:nowrap" class="ft83"><b>Figure</b>&#160;<b>5.&#160;&#160;</b>Additional controllable degrees of freedom will allow shape changing robots to approach the capabilities of biological&#160;systems. Current&#160;</p>
<p style="position:absolute;top:280px;left:72px;white-space:nowrap" class="ft85">shape changing robots leverage relatively few controllable degrees of freedom (DoFs) to adapt, while some biological organisms leverage dozens of&#160;</p>
<p style="position:absolute;top:294px;left:72px;white-space:nowrap" class="ft85">independent DoFs during normal motions, and growth allows organisms countless independent DoFs for changing their shape. Left to right: Morphing&#160;</p>
<p style="position:absolute;top:308px;left:72px;white-space:nowrap" class="ft85">wheel;&#160;clay-sculpting&#160;morphing&#160;robot;&#160;voxel-based&#160;robots;&#160;octopus&#160;squeezing&#160;through&#160;a&#160;1-inch&#160;diameter&#160;hole;&#160;tadpole-to-adult&#160;transition&#160;for&#160;a&#160;Microhyla&#160;</p>
<p style="position:absolute;top:322px;left:72px;white-space:nowrap" class="ft85">fissipes frog. Image for morphing wheel: Adapted with permission.[28]&#160;Copyright 2017, Mary Ann Liebert, Inc. Image for morphing robots: Adapted&#160;</p>
<p style="position:absolute;top:337px;left:72px;white-space:nowrap" class="ft85">with&#160;permission.[30]&#160;Copyright&#160;2019,&#160;IEEE.&#160;Image&#160;for&#160;voxel-based&#160;robots:&#160;Adapted&#160;with&#160;permission.[31]&#160;Copyright&#160;2019,&#160;Sam&#160;Kriegman.&#160;Octopus&#160;image:&#160;</p>
<p style="position:absolute;top:351px;left:72px;white-space:nowrap" class="ft85">Reproduced with permission.[114]&#160;Copyright 2012, James B. Wood. Frog image: Reproduced under the terms of the CC-BY Creative Commons Attribution&#160;</p>
<p style="position:absolute;top:365px;left:72px;white-space:nowrap" class="ft85"><a href="https://creativecommons.org/licenses/by/4.0/">International License (https://creativecommons.org/licenses/by/4.0/).</a>[142]&#160;Copyright 2019, The Authors, published by Frontiers.</p>
<p style="position:absolute;top:1112px;left:72px;white-space:nowrap" class="ft87"><i>Adv.</i>&#160;<i>Mater.</i>&#160;<b>2020</b>, 2002882</p>
</div>
</body>
</html>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
<title>c01e2e7a02cda03fa7acf91fcfdbb4ca-html.html</title>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
 <br/>
<style type="text/css">
<!--
	p {margin: 0; padding: 0;}	.ft90{font-size:7px;font-family:Times;color:#231f20;}
	.ft91{font-size:8px;font-family:Times;color:#231f20;}
	.ft92{font-size:11px;font-family:Times;color:#231f20;}
	.ft93{font-size:10px;font-family:Times;color:#231f20;}
	.ft94{font-size:11px;font-family:Times;color:#231f20;}
	.ft95{font-size:15px;font-family:Times;color:#231f20;}
	.ft96{font-size:10px;font-family:Times;color:#231f20;}
	.ft97{font-size:6px;font-family:Times;color:#231f20;}
	.ft98{font-size:8px;font-family:Times;color:#231f20;}
	.ft99{font-size:8px;font-family:Times;color:#231f20;}
	.ft910{font-size:11px;line-height:16px;font-family:Times;color:#231f20;}
	.ft911{font-size:15px;line-height:30px;font-family:Times;color:#231f20;}
-->
</style>
</head>
<body bgcolor="#A0A0A0" vlink="blue" link="blue">
<div id="page9-div" style="position:relative;width:892px;height:1173px;">
<p style="position:absolute;top:1112px;left:704px;white-space:nowrap" class="ft90">©&#160;2020 Wiley-VCH GmbH</p>
<p style="position:absolute;top:1108px;left:399px;white-space:nowrap" class="ft92"><b>2002882&#160;&#160;(9 of 12)</b></p>
<p style="position:absolute;top:64px;left:743px;white-space:nowrap" class="ft93"><b>www.advmat.de</b></p>
<p style="position:absolute;top:64px;left:77px;white-space:nowrap" class="ft93"><b>www.advancedsciencenews.com</b></p>
<p style="position:absolute;top:698px;left:77px;white-space:nowrap" class="ft910">robots.[34]&#160;However, the load-bearing capabilities of many of&#160;<br/>these systems are low, and the remaining systems have limited&#160;<br/>controllability and ability to grow into unplanned geometries.</p>
<p style="position:absolute;top:747px;left:92px;white-space:nowrap" class="ft94">Variable modulus materials (reviewed by Manti et &#160;al.[131])&#160;</p>
<p style="position:absolute;top:764px;left:77px;white-space:nowrap" class="ft910">can also potentially be used to control the deformation of sec-<br/>tions during shape change,&#160;improve load-bearing capabili-<br/>ties, and reduce energy requirements. For example, one robot&#160;<br/>selectively stiffened sections of its&#160;outer membrane&#160;to direct&#160;<br/>deformation when the inner chamber was inflated, producing&#160;<br/>locomotion (<b>Figure</b> &#160;<b>6</b>a).[132]&#160;Granular jamming, used in this&#160;<br/>example, is stretchable but generally has low tensile modulus&#160;<br/>relative to other state-of-the-art variable stiffness materials,&#160;<br/>including conductive epoxies[133]&#160;and laminar jamming.[134,135]&#160;<br/>Unfortunately,&#160;these&#160;alternative&#160;materials&#160;do&#160;not&#160;perform&#160;well&#160;<br/>over&#160;tensile&#160;strains&#160;larger&#160;than&#160;a&#160;few&#160;percent.&#160;Recent&#160;advances&#160;<br/>such as cutting serpentine patterns in layer jamming sheets&#160;<br/>to allow stretch in one direction,[18]&#160;and low-melting-point-<br/>alloy inclusions in a silicone matrix[136]&#160;(Figure &#160;6b) have the&#160;<br/>potential to allow robots to control their stiffness while con-<br/>trolling large strains during shape change. By leveraging vari-<br/>able stiffness strategies such as layer jamming,[134,135]&#160;granular&#160;<br/>jamming,[8,18]&#160;or variable stiffness materials such as thermoset&#160;<br/>polymers,[133]&#160;robots could also increase their load-bearing&#160;</p>
<p style="position:absolute;top:698px;left:459px;white-space:nowrap" class="ft910">capabilities in each attained shape, without requiring re-<br/>adaptation of control strategy. For example, in the turtle- and&#160;<br/>tortoise-inspired morphing&#160;limb proposed&#160;by Baines et al., the&#160;<br/>robot could hold a flipper-like shape for hydrodynamically effi-<br/>cient swimming, and switch to a load-bearing leg-like shape&#160;<br/>for walking&#160;using a softening/stiffening thermoset&#160;epoxy&#160;<br/>(Figure &#160;6c).[77,78]&#160;Stiffening could also allow a robot to lock&#160;<br/>in its shape and disengage its morphing actuators, to reduce&#160;<br/>energy requirements. Researchers have shown this concept&#160;<br/>in various applications, including using a variable stiffness&#160;<br/>conductive epoxy composite to selectively soften and stiffen a&#160;<br/>gripper to maintain the position of its payload without addi-<br/>tional energy input or control loops.[133]&#160;In other examples,&#160;<br/>researchers&#160;employed layer[137]&#160;and granular jamming[138]&#160;to&#160;<br/>selectively soften and stiffen continuum manipulators to hold&#160;<br/>a pose.</p>
<p style="position:absolute;top:997px;left:459px;white-space:nowrap" class="ft910"><b>6. Conclusions and Outlook<br/></b>We have surveyed the literature related to shape changing&#160;<br/>robots,&#160;from bioinspiration&#160;to&#160;simulation and&#160;hardware&#160;<br/>implementation. By actively morphing into different shapes,&#160;</p>
<p style="position:absolute;top:583px;left:77px;white-space:nowrap" class="ft93"><b>Figure</b>&#160;<b>6.&#160;&#160;</b>Variable modulus materials can allow robots to tune their morphing trajectories and selectively maintain desirable shapes. a)&#160;Granular jam-</p>
<p style="position:absolute;top:598px;left:77px;white-space:nowrap" class="ft96">ming allowed an air-filled robot to selectively control its expansion (left) and generate a wide range of shapes (right) for&#160;locomotion. Adapted with&#160;</p>
<p style="position:absolute;top:612px;left:77px;white-space:nowrap" class="ft96">permission.[132]&#160;Copyright 2009, IEEE. b) Low-melting-point-alloy inclusions in a silicone matrix allowed reversible morphing and shape memory&#160;in&#160;</p>
<p style="position:absolute;top:626px;left:77px;white-space:nowrap" class="ft96">arbitrary geometries. The images show how the “switchable stretchability”&#160;material could tune the trajectory of a single inflatable actuator. Reproduced&#160;</p>
<p style="position:absolute;top:640px;left:77px;white-space:nowrap" class="ft96">with permission.[136]&#160;Copyright 2019, Wiley-VCH. c) Variable stiffness material embedded in a morphing limb was used for softening during shape&#160;</p>
<p style="position:absolute;top:655px;left:77px;white-space:nowrap" class="ft96">change, and stiffening to hold either a flipper or leg shape in aquatic and terrestrial environments, respectively. Tortoise and flipper images on the&#160;</p>
<p style="position:absolute;top:669px;left:77px;white-space:nowrap" class="ft96">right: Adapted with permission.[78]&#160;Copyright 2020, IOP Publishing. The turtle image is from Pixabay.</p>
<p style="position:absolute;top:1112px;left:77px;white-space:nowrap" class="ft98"><i>Adv.</i>&#160;<i>Mater.</i>&#160;<b>2020</b>, 2002882</p>
</div>
</body>
</html>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
<title>c01e2e7a02cda03fa7acf91fcfdbb4ca-html.html</title>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
 <br/>
<style type="text/css">
<!--
	p {margin: 0; padding: 0;}	.ft100{font-size:7px;font-family:Times;color:#231f20;}
	.ft101{font-size:8px;font-family:Times;color:#231f20;}
	.ft102{font-size:11px;font-family:Times;color:#231f20;}
	.ft103{font-size:10px;font-family:Times;color:#231f20;}
	.ft104{font-size:11px;font-family:Times;color:#231f20;}
	.ft105{font-size:15px;font-family:Times;color:#231f20;}
	.ft106{font-size:10px;font-family:Times;color:#231f20;}
	.ft107{font-size:10px;font-family:Times;color:#231f20;}
	.ft108{font-size:8px;font-family:Times;color:#231f20;}
	.ft109{font-size:8px;font-family:Times;color:#231f20;}
	.ft1010{font-size:11px;line-height:16px;font-family:Times;color:#231f20;}
	.ft1011{font-size:15px;line-height:28px;font-family:Times;color:#231f20;}
	.ft1012{font-size:10px;line-height:15px;font-family:Times;color:#231f20;}
	.ft1013{font-size:10px;line-height:15px;font-family:Times;color:#231f20;}
-->
</style>
</head>
<body bgcolor="#A0A0A0" vlink="blue" link="blue">
<div id="page10-div" style="position:relative;width:892px;height:1173px;">
<p style="position:absolute;top:1112px;left:701px;white-space:nowrap" class="ft100">©&#160;2020 Wiley-VCH GmbH</p>
<p style="position:absolute;top:1108px;left:392px;white-space:nowrap" class="ft102"><b>2002882&#160;&#160;(10 of 12)</b></p>
<p style="position:absolute;top:64px;left:739px;white-space:nowrap" class="ft103"><b>www.advmat.de</b></p>
<p style="position:absolute;top:64px;left:72px;white-space:nowrap" class="ft103"><b>www.advancedsciencenews.com</b></p>
<p style="position:absolute;top:104px;left:72px;white-space:nowrap" class="ft1010">many state-of-the-art robots have been shown to expand their&#160;<br/>capabilities by gaining new locomotion modes,[28,75]&#160;avoiding&#160;<br/>obstacles,[30]&#160;or transitioning between body shapes suitable&#160;<br/>for swimming or walking.[77,78]&#160;Increased closed-loop control&#160;<br/>of morphology and material properties could eventually allow&#160;<br/>robots to rival the dynamic plasticity attained by natural sys-<br/>tems. However, many open questions remain regarding when,&#160;<br/>how, and to what degree shape change is useful.</p>
<p style="position:absolute;top:236px;left:87px;white-space:nowrap" class="ft104">The phenomenon of shape change overlaps with consid-</p>
<p style="position:absolute;top:252px;left:72px;white-space:nowrap" class="ft1010">erations of adaptation at differing spatial and temporal scales.&#160;<br/>Spatially, for example, a rigid robot&#160;may experience local shape&#160;<br/>change at a joint, but none within the rigid segments from&#160;<br/>which it is comprised. In contrast, a soft robot may change&#160;<br/>its shape at all relevant length scales, globally and locally.&#160;<br/>Organisms[6]&#160;or robots[120]&#160;capable of physical developmental&#160;<br/>change may change their body plans slowly over their lifetimes,&#160;<br/>while&#160;faster, local deformations&#160;may&#160;occur&#160;at&#160;joints during&#160;<br/>specific behaviors. Consideration of how to seamlessly model&#160;<br/>and integrate such capabilities into the design of robots across&#160;<br/>length scales, while simultaneously balancing traditional design&#160;<br/>goals such as velocity, payload, and force output, remains a&#160;<br/>largely unsolved problem.</p>
<p style="position:absolute;top:467px;left:87px;white-space:nowrap" class="ft104">Much&#160;can&#160;be&#160;gained&#160;in&#160;future&#160;research&#160;by&#160;exploiting&#160;les-</p>
<p style="position:absolute;top:483px;left:72px;white-space:nowrap" class="ft1010">sons&#160;of&#160;robustness&#160;from&#160;biology.&#160;A&#160;key&#160;component&#160;of&#160;biolog-<br/>ical embedded control is its multiscale goal-seeking nature.[139]&#160;<br/>Functional swarms—for example, termite colonies that main-<br/>tain a shared nest—are made of individual bodies that each&#160;<br/>build and repair to their particular target morphology. This is&#160;<br/>done by organs that maintain specific physiological and func-<br/>tional specifications, and tissues which deform to maintain&#160;<br/>histological targets. These are, in turn, made of cells which opti-<br/>mize various parameters as they migrate, proliferate, and differ-<br/>entiate.&#160;Inside&#160;the&#160;cells&#160;are&#160;genetic&#160;and&#160;metabolic&#160;networks&#160;that&#160;<br/>also have degrees of memory, robustness, and homeostasis.&#160;<br/>The ability of each nested level to have its own local morpho-<br/>genetic goals (in the cybernetic sense) contrasts with today’s&#160;<br/>robots, which are largely made of unintelligent parts, although&#160;<br/>some early examples of embedded distributed computation and&#160;<br/>soft logic gates are emerging.[140,141]</p>
<p style="position:absolute;top:747px;left:87px;white-space:nowrap" class="ft104">As demonstrated by this progress report, innovations in&#160;</p>
<p style="position:absolute;top:764px;left:72px;white-space:nowrap" class="ft1010">multifunctional materials, soft robotics, and evolutionary&#160;<br/>robotics are converging to make shape changing robots more&#160;<br/>viable. Such shape changing robots should be viewed as impor-<br/>tant model systems for evolutionary biology and regenerative&#160;<br/>medicine,[10]&#160;providing&#160;simplified&#160;“bodies”&#160;in&#160;which&#160;to&#160;test&#160;theo-<br/>ries&#160;of&#160;tissue&#160;computation,&#160;brain–body&#160;control,&#160;and&#160;regenerative&#160;<br/>algorithms, and in which to abstract the profound lessons of&#160;<br/>life-as-it-could-be&#160;from&#160;evolutionary&#160;contingencies.[33,34]&#160;Indeed,&#160;<br/>control&#160;of morphology is&#160;an&#160;unsolved&#160;problem in&#160;medicine—<br/>from fixing birth defects to traumatic injury repair, aging, and&#160;<br/>cancer. Thus, the question of shape and its dynamic control is&#160;<br/>an emerging new science at the intersection of&#160;evolution, bio-<br/>medicine, machine learning, and robotics.</p>
<p style="position:absolute;top:1020px;left:72px;white-space:nowrap" class="ft1011"><b>Acknowledgements<br/></b>This&#160;work&#160;was&#160;supported&#160;by&#160;an&#160;NSF&#160;Emerging&#160;Frontiers&#160;in&#160;Research&#160;</p>
<p style="position:absolute;top:1062px;left:72px;white-space:nowrap" class="ft106">and Innovation grant (# 1830870). D.S. was supported by a NASA Space&#160;</p>
<p style="position:absolute;top:1077px;left:72px;white-space:nowrap" class="ft106">Technology Research Fellowship (80NSSC17K0164).</p>
<p style="position:absolute;top:103px;left:455px;white-space:nowrap" class="ft1011"><b>Conflict of Interest<br/></b>The authors declare no conflict of interest.</p>
<p style="position:absolute;top:189px;left:455px;white-space:nowrap" class="ft1011"><b>Keywords<br/></b>anatomical homeostasis, evolutionary robotics, morphing robots,&#160;</p>
<p style="position:absolute;top:232px;left:455px;white-space:nowrap" class="ft106">reconfigurable robots,&#160;regeneration, smart materials, soft robotics,&#160;</p>
<p style="position:absolute;top:246px;left:455px;white-space:nowrap" class="ft106">synthetic morphogenesis</p>
<p style="position:absolute;top:274px;left:698px;white-space:nowrap" class="ft106">Received:&#160;April 28, 2020</p>
<p style="position:absolute;top:289px;left:712px;white-space:nowrap" class="ft106">Revised:&#160;June 1, 2020</p>
<p style="position:absolute;top:304px;left:724px;white-space:nowrap" class="ft106">Published online:&#160;</p>
<p style="position:absolute;top:372px;left:468px;white-space:nowrap" class="ft106">[1]&#160;&#160;K. J. Quillin,&#160;<i>J. Exp. Biol.</i>&#160;<b>1999</b>,&#160;<i>202</i>, 661.</p>
<p style="position:absolute;top:387px;left:467px;white-space:nowrap" class="ft1012">[2]&#160;&#160;R. H. Armour, J. F. V. Vincent,&#160;<i>J. Bionic Eng.</i>&#160;<b>2006</b>,&#160;<i>3</i>, 195.<br/>[3]&#160;&#160;M. Levin, A. M. Pietak, J. Bischof,&#160;<i>Semin. Cell Dev. Biol.</i>&#160;<b>2019</b>,&#160;<i>87</i>,&#160;</p>
<p style="position:absolute;top:417px;left:485px;white-space:nowrap" class="ft106">125.</p>
<p style="position:absolute;top:432px;left:468px;white-space:nowrap" class="ft106">[4]&#160;&#160;C. McCusker, C. McCusker, D. M. Gardiner,&#160;<i>Gerontology</i>&#160;<b>2011</b>,&#160;<i>57</i>,&#160;</p>
<p style="position:absolute;top:447px;left:485px;white-space:nowrap" class="ft106">565.</p>
<p style="position:absolute;top:462px;left:467px;white-space:nowrap" class="ft106">[5]&#160;&#160;D. J. Blackiston, T. Shomrat, M. Levin,&#160;<i>Commun. Integr. Biol.</i>&#160;<b>2015</b>,&#160;</p>
<p style="position:absolute;top:477px;left:485px;white-space:nowrap" class="ft107"><i>8</i>, e1073424.</p>
<p style="position:absolute;top:492px;left:467px;white-space:nowrap" class="ft106">[6]&#160;&#160;A. Tung, M. Levin,&#160;<i>Dev. Biol. (Amsterdam, Neth.)</i>&#160;<b>2020</b>,&#160;<i>461</i>, 1.</p>
<p style="position:absolute;top:507px;left:468px;white-space:nowrap" class="ft106">[7]&#160;&#160;M. &#160;Yim, W. m. &#160;Shen, B. &#160;Salemi, D. &#160;Rus, M. &#160;Moll, H. &#160;Lipson,&#160;</p>
<p style="position:absolute;top:522px;left:485px;white-space:nowrap" class="ft106">E. Klavins, G. S. Chirikjian,&#160;<i>IEEE Rob. Autom.</i>&#160;<b>2007</b>,&#160;<i>14</i>, 43.</p>
<p style="position:absolute;top:537px;left:467px;white-space:nowrap" class="ft106">[8]&#160;&#160;E. &#160;Brown, N. &#160;Rodenberg, J. &#160;Amend, A. &#160;Mozeika, E. &#160;Steltz,&#160;</p>
<p style="position:absolute;top:552px;left:485px;white-space:nowrap" class="ft1012">M. R. &#160;Zakin, H. &#160;Lipson, H. M. &#160;Jaeger,&#160;<i>Proc. Natl. Acad. Sci. USA</i>&#160;<br/><b>2010</b>,&#160;<i>107</i>, 18809.</p>
<p style="position:absolute;top:582px;left:467px;white-space:nowrap" class="ft106">[9]&#160;&#160;J. W. &#160;Booth, D. &#160;Shah, J. C. &#160;Case, E. L. &#160;White, M. C. &#160;Yuen,&#160;</p>
<p style="position:absolute;top:582px;left:816px;white-space:nowrap" class="ft106">&#160;</p>
<p style="position:absolute;top:597px;left:485px;white-space:nowrap" class="ft106">O. Cyr-Choiniere, R. Kramer-Bottiglio,&#160;<i>Sci. Rob.</i>&#160;<b>2018</b>,&#160;<i>3</i>, eaat1853.</p>
<p style="position:absolute;top:612px;left:462px;white-space:nowrap" class="ft106">[10]&#160;&#160;I. &#160;Slavkov, D. &#160;Carrillo-Zapata, N. &#160;Carranza, X. &#160;Diego, F. &#160;Jansson,&#160;</p>
<p style="position:absolute;top:627px;left:485px;white-space:nowrap" class="ft106">J. Kaandorp, S. Hauert, J. Sharpe,&#160;<i>Sci. Rob.</i>&#160;<b>2018</b>,&#160;<i>3</i>, 25.</p>
<p style="position:absolute;top:642px;left:464px;white-space:nowrap" class="ft106">[11]&#160;&#160;F. &#160;Giorgio-Serchi, A. &#160;Arienti, F. &#160;Corucci, M. &#160;Giorelli, C. &#160;Laschi,&#160;</p>
<p style="position:absolute;top:657px;left:485px;white-space:nowrap" class="ft107"><i>Bioinspir. Biomim.</i>&#160;<b>2017</b>,&#160;<i>12</i>, 025007.</p>
<p style="position:absolute;top:672px;left:462px;white-space:nowrap" class="ft106">[12]&#160;&#160;A. J. Ijspeert, A. Crespi, D. Ryczko, J.-M. Cabelguen,&#160;<i>Science</i>&#160;<b>2007</b>,&#160;</p>
<p style="position:absolute;top:687px;left:485px;white-space:nowrap" class="ft107"><i>315</i>, 1416.</p>
<p style="position:absolute;top:702px;left:463px;white-space:nowrap" class="ft106">[13]&#160;&#160;H. Marvi,&#160;C. Gong,&#160;N. Gravish,&#160;H. Astley,&#160;M. Travers,&#160;R.&#160;L. Hatton,&#160;</p>
<p style="position:absolute;top:717px;left:485px;white-space:nowrap" class="ft1012">J.&#160;R. Mendelson,&#160;H. Choset, D.&#160;L. Hu,&#160;D. I. Goldman,&#160;<i>Science</i>&#160;<b>2014</b>,&#160;<br/><i>346</i>, 224.</p>
<p style="position:absolute;top:747px;left:463px;white-space:nowrap" class="ft106">[14]&#160;&#160;J. &#160;Yosinski, J. &#160;Clune, Y. &#160;Bengio, H. &#160;Lipson, in&#160;<i>Advances in&#160;</i></p>
<p style="position:absolute;top:762px;left:485px;white-space:nowrap" class="ft1012"><i>Neural Information Processing Systems 27</i>, (Eds: Z. Ghahramani,&#160;&#160;<br/>M. Welling, C. Cortes, N. D. Lawrence, K. Q. Weinberger), Curran&#160;<br/>Associates, Inc., New York&#160;<b>2014</b>, pp. 3320–3328.</p>
<p style="position:absolute;top:807px;left:462px;white-space:nowrap" class="ft1012">[15]&#160;&#160;S. Hirose, Y. Umetani,&#160;<i>Mech. Mach. Theory</i>&#160;<b>1978</b>,&#160;<i>13</i>, 351.<br/>[16]&#160;&#160;I. D. Walker, D. M. Dawson, T. Flash, F. W. Grasso, R. T. Hanlon,&#160;</p>
<p style="position:absolute;top:837px;left:485px;white-space:nowrap" class="ft1012">B. Hochner,&#160;W.&#160;M. Kier,&#160;C.&#160;C. Pagano,&#160;C.&#160;D. Rahn,&#160;Q.&#160;M. Zhang,&#160;In&#160;<br/><i>Proc. SPIE</i>&#160;<b>2005</b>,&#160;<i>5804</i>, 303.</p>
<p style="position:absolute;top:867px;left:463px;white-space:nowrap" class="ft106">[17]&#160;&#160;F. &#160;Ilievski, A. D. &#160;Mazzeo, R. F. &#160;Shepherd, X. &#160;Chen,&#160;</p>
<p style="position:absolute;top:882px;left:485px;white-space:nowrap" class="ft106">G. M. Whitesides,&#160;<i>Angew. Chem.</i>&#160;<b>2011</b>,&#160;<i>123</i>, 1930.</p>
<p style="position:absolute;top:897px;left:462px;white-space:nowrap" class="ft106">[18]&#160;&#160;V. &#160;Wall, R. &#160;Deimel, O. &#160;Brock, presented at&#160;<i>2015 IEEE Int. Conf.&#160;</i></p>
<p style="position:absolute;top:912px;left:485px;white-space:nowrap" class="ft107"><i>Robotics and Automation (ICRA)</i>, Paris, France, May&#160;<b>2015</b>.</p>
<p style="position:absolute;top:927px;left:462px;white-space:nowrap" class="ft106">[19]&#160;&#160;N. R. Sinatra, C. B. Teeple, D. M. Vogt, K. K. Parker, D. F. Gruber,&#160;</p>
<p style="position:absolute;top:942px;left:485px;white-space:nowrap" class="ft106">R. J. Wood,&#160;<i>Sci. Rob.</i>&#160;<b>2019</b>,&#160;<i>4</i>, eaax5425.</p>
<p style="position:absolute;top:957px;left:461px;white-space:nowrap" class="ft106">[20]&#160;&#160;B. &#160;Shih, D. &#160;Drotman, C. &#160;Christianson, Z. &#160;Huo, R. &#160;White,&#160;</p>
<p style="position:absolute;top:972px;left:485px;white-space:nowrap" class="ft1012">H. I. &#160;Christensen, M. T. &#160;Tolley, presented at&#160;<i>2017 IEEE/RSJ Int.&#160;<br/>Conf. Intelligent Robots and Systems (IROS)</i>, Vancouver, Canada&#160;<br/><b>2017</b>.</p>
<p style="position:absolute;top:1017px;left:462px;white-space:nowrap" class="ft106">[21]&#160;&#160;S. Kim, C. Laschi, B. Trimmer,&#160;<i>Trends Biotechnol.</i>&#160;<b>2013</b>,&#160;<i>31</i>, 287.</p>
<p style="position:absolute;top:1032px;left:461px;white-space:nowrap" class="ft1012">[22]&#160;&#160;D. Rus, M. T. Tolley,&#160;<i>Nature</i>&#160;<b>2015</b>,&#160;<i>521</i>, 467.<br/>[23]&#160;&#160;M. Cianchetti, C. Laschi, A. Menciassi, P. Dario,&#160;<i>Nat. Rev. Mater.</i>&#160;</p>
<p style="position:absolute;top:1062px;left:485px;white-space:nowrap" class="ft103"><b>2018</b>,&#160;<i>3</i>, 143.</p>
<p style="position:absolute;top:1077px;left:462px;white-space:nowrap" class="ft106">[24]&#160;&#160;C. Laschi, B. Mazzolai, M. Cianchetti,&#160;<i>Sci. Rob.</i>&#160;<b>2016</b>,&#160;<i>1</i>, eaah3690.</p>
<p style="position:absolute;top:1112px;left:72px;white-space:nowrap" class="ft108"><i>Adv.</i>&#160;<i>Mater.</i>&#160;<b>2020</b>, 2002882</p>
</div>
</body>
</html>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
<title>c01e2e7a02cda03fa7acf91fcfdbb4ca-html.html</title>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
 <br/>
<style type="text/css">
<!--
	p {margin: 0; padding: 0;}	.ft110{font-size:7px;font-family:Times;color:#231f20;}
	.ft111{font-size:8px;font-family:Times;color:#231f20;}
	.ft112{font-size:11px;font-family:Times;color:#231f20;}
	.ft113{font-size:10px;font-family:Times;color:#231f20;}
	.ft114{font-size:10px;font-family:Times;color:#231f20;}
	.ft115{font-size:10px;font-family:Times;color:#231f20;}
	.ft116{font-size:8px;font-family:Times;color:#231f20;}
	.ft117{font-size:8px;font-family:Times;color:#231f20;}
	.ft118{font-size:10px;line-height:15px;font-family:Times;color:#231f20;}
	.ft119{font-size:10px;line-height:15px;font-family:Times;color:#231f20;}
	.ft1110{font-size:10px;line-height:14px;font-family:Times;color:#231f20;}
-->
</style>
</head>
<body bgcolor="#A0A0A0" vlink="blue" link="blue">
<div id="page11-div" style="position:relative;width:892px;height:1173px;">
<p style="position:absolute;top:1112px;left:704px;white-space:nowrap" class="ft110">©&#160;2020 Wiley-VCH GmbH</p>
<p style="position:absolute;top:1108px;left:397px;white-space:nowrap" class="ft112"><b>2002882&#160;&#160;(11 of 12)</b></p>
<p style="position:absolute;top:64px;left:743px;white-space:nowrap" class="ft113"><b>www.advmat.de</b></p>
<p style="position:absolute;top:64px;left:77px;white-space:nowrap" class="ft113"><b>www.advancedsciencenews.com</b></p>
<p style="position:absolute;top:104px;left:83px;white-space:nowrap" class="ft118">[25]&#160;&#160;L. Wang, F. Iida,&#160;<i>IEEE Rob. Autom.</i>&#160;<b>2015</b>,&#160;<i>22</i>, 125.<br/>[26]&#160;&#160;S. Yim, M. Sitti,&#160;<i>IEEE Trans. Rob.</i>&#160;<b>2012</b>,&#160;<i>28</i>, 1198.</p>
<p style="position:absolute;top:134px;left:83px;white-space:nowrap" class="ft114">[27]&#160;&#160;S. Yim, M. Sitti,&#160;<i>IEEE Trans. Rob.</i>&#160;<b>2012</b>,&#160;<i>28</i>, 183.</p>
<p style="position:absolute;top:150px;left:83px;white-space:nowrap" class="ft114">[28]&#160;&#160;D.-Y. Lee, S.-R. Kim, J.-S. Kim, J.-J. Park, K.-J. Cho,&#160;<i>Soft Robot.</i>&#160;<b>2017</b>,&#160;</p>
<p style="position:absolute;top:165px;left:107px;white-space:nowrap" class="ft115"><i>4</i>, 163.</p>
<p style="position:absolute;top:180px;left:83px;white-space:nowrap" class="ft114">[29]&#160;&#160;T. F. Nygaard, C. P. Martin, J. Torresen, K. Glette, presented at&#160;<i>2019&#160;</i></p>
<p style="position:absolute;top:195px;left:107px;white-space:nowrap" class="ft115"><i>Int. Conf. Robotics and Automation (ICRA)</i>, Montreal, Canada&#160;<b>2019</b>.</p>
<p style="position:absolute;top:210px;left:83px;white-space:nowrap" class="ft114">[30]&#160;&#160;D. S. Shah, M. C. Yuen, L. G. Tilton, E. J. Yang, R. Kramer-Bottiglio,&#160;</p>
<p style="position:absolute;top:226px;left:107px;white-space:nowrap" class="ft115"><i>IEEE Robot. Autom. Lett.</i>&#160;<b>2019</b>,&#160;<i>4</i>, 2204.</p>
<p style="position:absolute;top:241px;left:84px;white-space:nowrap" class="ft114">[31]&#160;&#160;S. &#160;Kriegman, S. &#160;Walker, D. &#160;Shah, M. &#160;Levin, R. &#160;Kramer-Bottiglio,&#160;</p>
<p style="position:absolute;top:256px;left:107px;white-space:nowrap" class="ft118">J. &#160;Bongard,&#160;&#160;<i>Robotics:&#160;Science and Systems</i>, Freiburg im&#160;Breisgau,&#160;<br/>Germany&#160;<b>2019</b>.</p>
<p style="position:absolute;top:286px;left:83px;white-space:nowrap" class="ft118">[32]&#160;&#160;A. A. Taha, A. Hanbury,&#160;<i>BMC Med. Imaging</i>&#160;<b>2015</b>,&#160;<i>15</i>, 29.<br/>[33]&#160;&#160;J. Mustard, M. Levin,&#160;<i>Soft Rob.</i>&#160;<b>2014</b>,&#160;<i>1</i>, 169.</p>
<p style="position:absolute;top:317px;left:84px;white-space:nowrap" class="ft114">[34]&#160;&#160;R. Doursat, C. Sánchez,&#160;<i>Soft Rob.</i>&#160;<b>2014</b>,&#160;<i>1</i>, 110.</p>
<p style="position:absolute;top:332px;left:83px;white-space:nowrap" class="ft118">[35]&#160;&#160;J. C. Bongard,&#160;<i>Commun. ACM</i>&#160;<b>2013</b>,&#160;<i>56</i>, 74.<br/>[36]&#160;&#160;P. Koehl, J. Hass,&#160;<i>J. R. Soc., Interface</i>&#160;<b>2015</b>,&#160;<i>12</i>, 20150795.</p>
<p style="position:absolute;top:362px;left:84px;white-space:nowrap" class="ft114">[37]&#160;&#160;A. &#160;Hermanis, R. &#160;Cacurs, M. &#160;Greitans,&#160;<i>IEEE Sens. J.</i>&#160;&#160;<b>2016</b>,&#160;&#160;<i>16</i>,&#160;&#160;</p>
<p style="position:absolute;top:378px;left:107px;white-space:nowrap" class="ft114">1271.</p>
<p style="position:absolute;top:393px;left:83px;white-space:nowrap" class="ft114">[38]&#160;&#160;C. &#160;Rendl, D. &#160;Kim, S. &#160;Fanello, P. &#160;Parzer, C. &#160;Rhemann, J. &#160;Taylor,&#160;</p>
<p style="position:absolute;top:408px;left:107px;white-space:nowrap" class="ft119">M. Zirkl, G. Scheipl, T. Rothländer, M. Haller, S. Izadi, presented at&#160;&#160;<br/><i>Proc. 27th Annual&#160;ACM Symp. User Interface Software and Tech-<br/>nology</i>, UIST ‘14. ACM, Honolulu, HI, USA&#160;<b>2014</b>.</p>
<p style="position:absolute;top:453px;left:83px;white-space:nowrap" class="ft114">[39]&#160;&#160;T. Hoshi, H. Shinoda, presented at&#160;<i>2008 SICE Annual Conf.</i>, Tokyo,&#160;</p>
<p style="position:absolute;top:469px;left:107px;white-space:nowrap" class="ft114">Japan&#160;<b>2008</b>.</p>
<p style="position:absolute;top:484px;left:83px;white-space:nowrap" class="ft114">[40]&#160;&#160;P. &#160;Mittendorfer, G. &#160;Cheng, presented at&#160;<i>2012 IEEE/RSJ Int. Conf.&#160;</i></p>
<p style="position:absolute;top:499px;left:107px;white-space:nowrap" class="ft115"><i>Intelligent Robots and Systems</i>, Vilamoura, Portugal&#160;<b>2012</b>.</p>
<p style="position:absolute;top:514px;left:85px;white-space:nowrap" class="ft114">[41]&#160;&#160;T. L. T. Lun, K. Wang, J. D. L. Ho, K. Lee, K. Y. Sze, K. Kwok,&#160;<i>IEEE&#160;</i></p>
<p style="position:absolute;top:529px;left:107px;white-space:nowrap" class="ft115"><i>Robot. Autom. Lett.</i>&#160;<b>2019</b>,&#160;<i>4</i>, 1454.</p>
<p style="position:absolute;top:545px;left:83px;white-space:nowrap" class="ft114">[42]&#160;&#160;K. Caluwaerts,&#160;J. Bruce,&#160;J.&#160;M. Friesen,&#160;V. SunSpiral,&#160;presented&#160;at&#160;</p>
<p style="position:absolute;top:560px;left:107px;white-space:nowrap" class="ft118"><i>2016 IEEE Int. Conf. Robotics and Automation (ICRA)</i>, Stockholm,&#160;<br/>Sweden 2016.</p>
<p style="position:absolute;top:590px;left:84px;white-space:nowrap" class="ft114">[43]&#160;&#160;S. Kriegman, D. Blackiston, M. Levin, J. Bongard,&#160;<i>Proc. Natl. Acad.&#160;</i></p>
<p style="position:absolute;top:605px;left:107px;white-space:nowrap" class="ft115"><i>Sci. USA</i>&#160;<b>2020</b>,&#160;<i>117</i>, 1853.</p>
<p style="position:absolute;top:621px;left:84px;white-space:nowrap" class="ft114">[44]&#160;&#160;G. Pezzulo, M. Levin,&#160;<i>J. R. Soc., Interface</i>&#160;<b>2016</b>,&#160;<i>13</i>, 20160555.</p>
<p style="position:absolute;top:636px;left:83px;white-space:nowrap" class="ft118">[45]&#160;&#160;F. Baluška, M. Levin,&#160;<i>Front. Psychol.</i>&#160;<b>2016</b>,&#160;<i>7</i>, 902.<br/>[46]&#160;&#160;F. Keijzer, M. van Duijn, P. Lyon,&#160;<i>Adapt. Behav.</i>&#160;<b>2013</b>,&#160;<i>21</i>, 67.</p>
<p style="position:absolute;top:666px;left:84px;white-space:nowrap" class="ft114">[47]&#160;&#160;C. Fields, J. Bischof, M. Levin,&#160;<i>Physiology</i>&#160;<b>2019</b>,&#160;<i>35</i>, 16.</p>
<p style="position:absolute;top:681px;left:83px;white-space:nowrap" class="ft114">[48]&#160;&#160;M. &#160;Levin, G. &#160;Pezzulo, J. M. &#160;Finkelstein,&#160;<i>Annu. Rev. Biomed. Eng.</i>&#160;</p>
<p style="position:absolute;top:697px;left:107px;white-space:nowrap" class="ft113"><b>2017</b>,&#160;<i>19</i>, 353.</p>
<p style="position:absolute;top:712px;left:83px;white-space:nowrap" class="ft114">[49]&#160;&#160;M. Levin,&#160;<i>J. Physiol.</i>&#160;<b>2014</b>,&#160;<i>592</i>, 2295.</p>
<p style="position:absolute;top:727px;left:83px;white-space:nowrap" class="ft114">[50]&#160;&#160;D. J. &#160;Blackiston, E. Silva &#160;Casey, M. R. &#160;Weiss,&#160;<i>PloS One</i>&#160;&#160;<b>2008</b>,&#160;&#160;<i>3</i>,&#160;</p>
<p style="position:absolute;top:742px;left:107px;white-space:nowrap" class="ft114">e1736.</p>
<p style="position:absolute;top:757px;left:84px;white-space:nowrap" class="ft114">[51]&#160;&#160;J. V. McConnell, A. L. Jacobson, D. P. Kimble,&#160;<i>J. Comp. Physiol. Psy-</i></p>
<p style="position:absolute;top:772px;left:107px;white-space:nowrap" class="ft115"><i>chol.</i>&#160;<b>1959</b>,&#160;<i>52</i>, 1.</p>
<p style="position:absolute;top:788px;left:83px;white-space:nowrap" class="ft118">[52]&#160;&#160;T. Shomrat, M. Levin,&#160;<i>J. Exp. Biol.</i>&#160;<b>2013</b>,&#160;<i>216</i>, 3799.<br/>[53]&#160;&#160;N. J. &#160;Oviedo, J. &#160;Morokuma, P. &#160;Walentek, I. P. &#160;Kema, M. B. &#160;Gu,&#160;</p>
<p style="position:absolute;top:818px;left:107px;white-space:nowrap" class="ft118">J.-M. Ahn, J. S. Hwang, T. Gojobori, M. Levin,&#160;<i>Dev. Biol.</i>&#160;<b>2010</b>,&#160;<i>339</i>,&#160;<br/>188.</p>
<p style="position:absolute;top:848px;left:83px;white-space:nowrap" class="ft114">[54]&#160;&#160;D. J. Blackiston, M. Levin,&#160;<i>J. Exp. Biol.</i>&#160;<b>2013</b>,&#160;<i>216</i>, 1031.</p>
<p style="position:absolute;top:864px;left:83px;white-space:nowrap" class="ft118">[55]&#160;&#160;P. Lyon,&#160;<i>Cogn. Process.</i>&#160;<b>2006</b>,&#160;<i>7</i>, 11.<br/>[56]&#160;&#160;S. Manicka, M. Levin,&#160;<i>Philos. Trans. R. Soc. B</i>&#160;<b>2019</b>,&#160;<i>374</i>, 20180369.</p>
<p style="position:absolute;top:894px;left:83px;white-space:nowrap" class="ft114">[57]&#160;&#160;S. Manicka, M. Levin,&#160;<i>Sci. Rep.</i>&#160;<b>2019</b>,&#160;<i>9</i>, 18612.</p>
<p style="position:absolute;top:909px;left:83px;white-space:nowrap" class="ft118">[58]&#160;&#160;H. Lipson, J. B. Pollack,&#160;<i>Nature</i>&#160;<b>2000</b>,&#160;<i>406</i>, 974.<br/>[59]&#160;&#160;D. &#160;Cellucci,&#160;R. &#160;MacCurdy,&#160;H. &#160;Lipson,&#160;S. &#160;Risi,&#160;<i>IEEE&#160;Robot.&#160;Autom.&#160;</i></p>
<p style="position:absolute;top:940px;left:107px;white-space:nowrap" class="ft115"><i>Lett.</i>&#160;<b>2017</b>,&#160;<i>2</i>, 1964.</p>
<p style="position:absolute;top:955px;left:83px;white-space:nowrap" class="ft114">[60]&#160;&#160;J. Hiller, H. Lipson,&#160;<i>IEEE Trans. Robot.</i>&#160;<b>2012</b>,&#160;<i>28</i>, 457.</p>
<p style="position:absolute;top:970px;left:84px;white-space:nowrap" class="ft114">[61]&#160;&#160;J. Hiller, H. Lipson,&#160;<i>Soft Rob.</i>&#160;<b>2014</b>,&#160;<i>1</i>, 88.</p>
<p style="position:absolute;top:985px;left:83px;white-space:nowrap" class="ft114">[62]&#160;&#160;S. Liu,&#160;D. Matthews,&#160;S. Kriegman,&#160;J. Bongard,&#160;Voxcraft-sim,&#160;a gpu-</p>
<p style="position:absolute;top:1000px;left:107px;white-space:nowrap" class="ft118"><a href="https://github.com/voxcraft/voxcraft-sim">accelerated voxel-based physics engine, https://github.com/vox-<br/>craft/voxcraft-sim (accessed: May 2020).</a></p>
<p style="position:absolute;top:1031px;left:83px;white-space:nowrap" class="ft114">[63]&#160;&#160;The Online Encyclopedia of Integer Sequences (nos. a000162 and&#160;</p>
<p style="position:absolute;top:1046px;left:107px;white-space:nowrap" class="ft114"><a href="https://oeis.org/A001931">a001931), https://oeis.org/A001931 (accessed: May 2020).</a></p>
<p style="position:absolute;top:1061px;left:83px;white-space:nowrap" class="ft114">[64]&#160;&#160;K. Sims,&#160;<i>Artif. Life</i>&#160;<b>1994</b>,&#160;<i>1</i>, 353.</p>
<p style="position:absolute;top:104px;left:465px;white-space:nowrap" class="ft118">[65]&#160;&#160;J. Bongard, V. Zykov, H. Lipson,&#160;<i>Science</i>&#160;<b>2006</b>,&#160;<i>314</i>, 1118.<br/>[66]&#160;&#160;J. &#160;Lehman, K. O. &#160;Stanley, presented at&#160;<i>Proc. 13th Annual Conf.&#160;</i></p>
<p style="position:absolute;top:134px;left:489px;white-space:nowrap" class="ft115"><i>Genetic and Evolutionary Computation</i>, New York&#160;<b>2011</b>.</p>
<p style="position:absolute;top:149px;left:466px;white-space:nowrap" class="ft114">[67]&#160;&#160;N. Cheney, J. Bongard, V. SunSpiral, H. Lipson,&#160;<i>J. R. Soc., Interface</i>&#160;</p>
<p style="position:absolute;top:164px;left:489px;white-space:nowrap" class="ft113"><b>2018</b>,&#160;<i>15</i>, 20170937.</p>
<p style="position:absolute;top:179px;left:465px;white-space:nowrap" class="ft114">[68]&#160;&#160;D. &#160;Pathak, C. &#160;Lu, T. &#160;Darrell, P. &#160;Isola, A. A. &#160;Efros, In H. Wallach,&#160;&#160;</p>
<p style="position:absolute;top:194px;left:489px;white-space:nowrap" class="ft118">H.&#160;Larochelle,&#160;A.&#160;Beygelzimer,&#160;F.&#160;d’Alché-Buc,&#160;E.&#160;Fox,&#160;R.&#160;Garnett&#160;&#160;<br/>(Eds).&#160;<i>Advances in Neural Information Processing Systems 32</i>, Curran&#160;<br/>Associates, Inc., New York&#160;<b>2019</b>, pp. 2295–2305.</p>
<p style="position:absolute;top:239px;left:465px;white-space:nowrap" class="ft114">[69]&#160;&#160;D. Ha,&#160;<i>Artif. Life</i>&#160;<b>2019</b>,&#160;<i>25</i>, 352.</p>
<p style="position:absolute;top:254px;left:466px;white-space:nowrap" class="ft114">[70]&#160;&#160;S. Kriegman,&#160;<i>Nat. Mach. Intell.</i>&#160;<b>2019</b>,&#160;<i>1</i>, 492.</p>
<p style="position:absolute;top:269px;left:467px;white-space:nowrap" class="ft114">[71]&#160;&#160;J. C. Bongard,&#160;<i>Proc. Natl. Acad. Sci. USA</i>&#160;<b>2011</b>,&#160;<i>108</i>, 1234.</p>
<p style="position:absolute;top:284px;left:466px;white-space:nowrap" class="ft114">[72]&#160;&#160;N. Cheney, J. Bongard, H. Lipson, presented at&#160;<i>Proc. 2015 Annual&#160;</i></p>
<p style="position:absolute;top:299px;left:489px;white-space:nowrap" class="ft119"><i>Conf. Genetic and Evolutionary Computation Conference - GECCO&#160;<br/>‘15</i>. Madrid, Spain&#160;<b>2015</b>.</p>
<p style="position:absolute;top:329px;left:466px;white-space:nowrap" class="ft114">[73]&#160;&#160;F. L. Moro, A. Spröwitz, A. Tuleu, M. Vespignani, N. G. Tsagarakis,&#160;</p>
<p style="position:absolute;top:344px;left:489px;white-space:nowrap" class="ft114">A. J. Ijspeert, D. G. Caldwell,&#160;<i>Biol. Cybern.</i>&#160;<b>2013</b>,&#160;<i>107</i>, 309.</p>
<p style="position:absolute;top:359px;left:467px;white-space:nowrap" class="ft114">[74]&#160;&#160;F. Flacco, T. Krager, A. D. Luca, O. Khatib, presented&#160;at&#160;<i>2012 IEEE&#160;</i></p>
<p style="position:absolute;top:374px;left:489px;white-space:nowrap" class="ft115"><i>Int. Conf. Robotics and Automation</i>, Saint Paul, MN, USA&#160;<b>2012</b>.</p>
<p style="position:absolute;top:389px;left:466px;white-space:nowrap" class="ft114">[75]&#160;&#160;H.-T. &#160;Lin, G. G. &#160;Leisk, B. &#160;Trimmer,&#160;<i>Bioinspir. Biomim.</i>&#160;&#160;<b>2011</b>,&#160;&#160;<i>6</i>,&#160;</p>
<p style="position:absolute;top:404px;left:489px;white-space:nowrap" class="ft114">026007.</p>
<p style="position:absolute;top:419px;left:466px;white-space:nowrap" class="ft114">[76]&#160;&#160;M. Ishida, D. Drotman, B. Shih, M. Hermes, M. Luhar, M. T. Tolley,&#160;</p>
<p style="position:absolute;top:434px;left:489px;white-space:nowrap" class="ft115"><i>IEEE Robot. Autom. Lett.</i>&#160;<b>2019</b>,&#160;<i>4</i>, 4163.</p>
<p style="position:absolute;top:449px;left:467px;white-space:nowrap" class="ft114">[77]&#160;&#160;R. L. Baines, J. W. Booth, F. E. Fish, R. Kramer-Bottiglio, presented at&#160;&#160;</p>
<p style="position:absolute;top:464px;left:489px;white-space:nowrap" class="ft118"><i>2019&#160;2nd IEEE&#160;Int.&#160;Conf.&#160;Soft Robotics&#160;(RoboSoft)</i>,&#160;Seoul,&#160;South&#160;<br/>Korea&#160;<b>2019</b>.</p>
<p style="position:absolute;top:494px;left:466px;white-space:nowrap" class="ft114">[78]&#160;&#160;R. Baines, S. Freeman, F. Fish, R. Kramer,&#160;<i>Bioinspir. Biomim.</i>&#160;<b>2020</b>,&#160;</p>
<p style="position:absolute;top:509px;left:489px;white-space:nowrap" class="ft115"><i>15</i>, 025002.</p>
<p style="position:absolute;top:524px;left:466px;white-space:nowrap" class="ft114">[79]&#160;&#160;E. &#160;Hawkes, B. &#160;An, N.&#160;M. &#160;Benbernou,&#160;H. &#160;Tanaka, S. &#160;Kim,&#160;</p>
<p style="position:absolute;top:539px;left:489px;white-space:nowrap" class="ft118">E. D. Demaine, D. Rus, R. J. Wood,&#160;<i>Proc. Natl. Acad. Sci. USA</i>&#160;<b>2010</b>,&#160;<br/><i>107</i>, 12441.</p>
<p style="position:absolute;top:569px;left:465px;white-space:nowrap" class="ft114">[80]&#160;&#160;D. Rus, M. T. Tolley,&#160;<i>Nat. Rev. Mater.</i>&#160;<b>2018</b>,&#160;<i>3</i>, 101.</p>
<p style="position:absolute;top:584px;left:467px;white-space:nowrap" class="ft114">[81]&#160;&#160;Y. &#160;Chen,&#160;H. &#160;Zhao,&#160;J. &#160;Mao,&#160;P. &#160;Chirarattananon,&#160;E.&#160;F. &#160;Helbling,&#160;</p>
<p style="position:absolute;top:599px;left:489px;white-space:nowrap" class="ft114">N.-S. P. Hyun, D. R. Clarke, R. J. Wood,&#160;<i>Nature</i>&#160;<b>2019</b>,&#160;<i>575</i>, 324.</p>
<p style="position:absolute;top:614px;left:465px;white-space:nowrap" class="ft114">[82]&#160;&#160;K. Y. Ma, P. Chirarattananon, S. B. Fuller, R. J. Wood,&#160;<i>Science</i>&#160;<b>2013</b>,&#160;</p>
<p style="position:absolute;top:629px;left:489px;white-space:nowrap" class="ft115"><i>340</i>, 603.</p>
<p style="position:absolute;top:644px;left:466px;white-space:nowrap" class="ft114">[83]&#160;&#160;B. &#160;Xu, X. &#160;Han, Y. &#160;Hu, Y. &#160;Luo, C.-H. &#160;Chen, Z. &#160;Chen, P. &#160;Shi,&#160;<i>Small</i>&#160;</p>
<p style="position:absolute;top:659px;left:489px;white-space:nowrap" class="ft113"><b>2019</b>,&#160;<i>15</i>, 1900006.</p>
<p style="position:absolute;top:674px;left:466px;white-space:nowrap" class="ft114">[84]&#160;&#160;A. A. Stanley, K. Hata, A. M. Okamura, presented at&#160;<i>2016 IEEE Int.&#160;</i></p>
<p style="position:absolute;top:689px;left:489px;white-space:nowrap" class="ft115"><i>Conf. Robotics and Automation (ICRA)</i>, Stockholm, Sweden&#160;<b>2016</b>.</p>
<p style="position:absolute;top:704px;left:465px;white-space:nowrap" class="ft114">[85]&#160;&#160;Y. &#160;Wang, C. &#160;Frazelle, R. &#160;Sirohi, L. &#160;Li, I. D. &#160;Walker, K. E. &#160;Green,&#160;</p>
<p style="position:absolute;top:719px;left:489px;white-space:nowrap" class="ft118">presented at&#160;<i>2019 Int. Conf. Robotics and Automation (ICRA)</i>,&#160;<br/>Montreal, Canada&#160;<b>2019</b>.</p>
<p style="position:absolute;top:749px;left:465px;white-space:nowrap" class="ft114">[86]&#160;&#160;M. Cooney, S. M. Karlsson,&#160;<i>PhyCS.</i>&#160;<b>2015</b>, pp. 118–123.</p>
<p style="position:absolute;top:764px;left:466px;white-space:nowrap" class="ft114">[87]&#160;&#160;D.&#160;S. Shah,&#160;J. Powers,&#160;L.&#160;G. Tilton,&#160;S. Kriegman,&#160;J. Bongard,&#160;<i>arXiv:&#160;</i></p>
<p style="position:absolute;top:779px;left:489px;white-space:nowrap" class="ft115"><i>2008.06397v1,</i>&#160;<b>2020</b>.</p>
<p style="position:absolute;top:794px;left:465px;white-space:nowrap" class="ft114">[88]&#160;&#160;T. &#160;George Thuruthel, Y. &#160;Ansari, E. &#160;Falotico, C. &#160;Laschi,&#160;<i>Soft Rob.</i>&#160;</p>
<p style="position:absolute;top:809px;left:489px;white-space:nowrap" class="ft113"><b>2018</b>,&#160;<i>5</i>, 149.</p>
<p style="position:absolute;top:824px;left:465px;white-space:nowrap" class="ft114">[89]&#160;&#160;J. J. Craig,&#160;<i>Introduction to Robotics: Mechanics and Control</i>, 3rd ed.,&#160;</p>
<p style="position:absolute;top:839px;left:489px;white-space:nowrap" class="ft114">Pearson Education India, Bengaluru, India&#160;<b>2009</b>.</p>
<p style="position:absolute;top:854px;left:465px;white-space:nowrap" class="ft114">[90]&#160;&#160;B. Shih, D. Shah, J. Li, T. G. Thuruthel, Y.-L. Park, F. Iida, Z. Bao,&#160;</p>
<p style="position:absolute;top:869px;left:489px;white-space:nowrap" class="ft114">R. Kramer-Bottiglio, M. T. Tolley,&#160;<i>Sci. Rob.</i>&#160;<b>2020</b>,&#160;<i>5</i>, eaaz9239.</p>
<p style="position:absolute;top:884px;left:467px;white-space:nowrap" class="ft114">[91]&#160;&#160;I. M. V. Meerbeek, C. M. D. Sa, R. F. Shepherd,&#160;<i>Sci. Rob.</i>&#160;<b>2018</b>,&#160;<i>3</i>,&#160;</p>
<p style="position:absolute;top:899px;left:489px;white-space:nowrap" class="ft114">eaau2489.</p>
<p style="position:absolute;top:914px;left:465px;white-space:nowrap" class="ft114">[92]&#160;&#160;E. L. &#160;White, M. C. &#160;Yuen, J. C. &#160;Case, R. K. &#160;Kramer,&#160;<i>Adv. Mater.&#160;</i></p>
<p style="position:absolute;top:929px;left:489px;white-space:nowrap" class="ft115"><i>Technol.</i>&#160;<b>2017</b>,&#160;<i>2</i>, 1700072.</p>
<p style="position:absolute;top:944px;left:466px;white-space:nowrap" class="ft118">[93]&#160;&#160;A. Tairych, I. A. Anderson,&#160;<i>Soft Rob.</i>&#160;<b>2019</b>, soro.2018.0055.<br/>[94]&#160;&#160;B. &#160;O’Brien, T. &#160;Gisby, I. A. &#160;Anderson,&#160;<i>Proc. SPIE</i>&#160;&#160;<b>2014</b>,&#160;&#160;<i>9056</i>,&#160;&#160;</p>
<p style="position:absolute;top:974px;left:489px;white-space:nowrap" class="ft114">905618.</p>
<p style="position:absolute;top:989px;left:465px;white-space:nowrap" class="ft114">[95]&#160;&#160;Z. &#160;Huang, Y. &#160;Hao, Y. &#160;Li, H. &#160;Hu, C. &#160;Wang, A. &#160;Nomoto, T. &#160;Pan,&#160;</p>
<p style="position:absolute;top:1004px;left:489px;white-space:nowrap" class="ft1110">Y. Gu, Y. Chen,&#160;T. Zhang, W. Li, Y. Lei,&#160;N. Kim,&#160;C. Wang, L. Zhang,&#160;<br/>J. W. &#160;Ward, A. &#160;Maralani, X. &#160;Li, M. F. &#160;Durstock, A. &#160;Pisano, Y. &#160;Lin,&#160;<br/>S. Xu,&#160;<i>Nat. Electron.</i>&#160;<b>2018</b>,&#160;<i>1</i>, 473.</p>
<p style="position:absolute;top:1049px;left:465px;white-space:nowrap" class="ft114">[96]&#160;&#160;S. Wang, J. Xu, W. Wang, G.-J. N. Wang, R. Rastak, F. Molina-Lopez,&#160;</p>
<p style="position:absolute;top:1064px;left:489px;white-space:nowrap" class="ft114">J. W. Chung, S. Niu, V. R. Feig, J. Lopez, T. Lei, S.-K. Kwon, Y. Kim,&#160;</p>
<p style="position:absolute;top:1112px;left:77px;white-space:nowrap" class="ft116"><i>Adv.</i>&#160;<i>Mater.</i>&#160;<b>2020</b>, 2002882</p>
</div>
</body>
</html>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
<title>c01e2e7a02cda03fa7acf91fcfdbb4ca-html.html</title>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
 <br/>
<style type="text/css">
<!--
	p {margin: 0; padding: 0;}	.ft120{font-size:7px;font-family:Times;color:#231f20;}
	.ft121{font-size:8px;font-family:Times;color:#231f20;}
	.ft122{font-size:11px;font-family:Times;color:#231f20;}
	.ft123{font-size:10px;font-family:Times;color:#231f20;}
	.ft124{font-size:10px;font-family:Times;color:#231f20;}
	.ft125{font-size:10px;font-family:Times;color:#231f20;}
	.ft126{font-size:8px;font-family:Times;color:#231f20;}
	.ft127{font-size:8px;font-family:Times;color:#231f20;}
	.ft128{font-size:10px;line-height:15px;font-family:Times;color:#231f20;}
	.ft129{font-size:10px;line-height:15px;font-family:Times;color:#231f20;}
-->
</style>
</head>
<body bgcolor="#A0A0A0" vlink="blue" link="blue">
<div id="page12-div" style="position:relative;width:892px;height:1173px;">
<p style="position:absolute;top:1112px;left:701px;white-space:nowrap" class="ft120">©&#160;2020 Wiley-VCH GmbH</p>
<p style="position:absolute;top:1108px;left:392px;white-space:nowrap" class="ft122"><b>2002882&#160;&#160;(12 of 12)</b></p>
<p style="position:absolute;top:64px;left:739px;white-space:nowrap" class="ft123"><b>www.advmat.de</b></p>
<p style="position:absolute;top:64px;left:72px;white-space:nowrap" class="ft123"><b>www.advancedsciencenews.com</b></p>
<p style="position:absolute;top:104px;left:102px;white-space:nowrap" class="ft128">A.&#160;M. &#160;Foudeh,&#160;A. &#160;Ehrlich,&#160;A. &#160;Gasperini,&#160;Y. &#160;Yun,&#160;B. &#160;Murmann,&#160;<br/>J. B.-H. Tok, Z. Bao,&#160;<i>Nature</i>&#160;<b>2018</b>,&#160;<i>555</i>, 83.</p>
<p style="position:absolute;top:134px;left:79px;white-space:nowrap" class="ft124">[97]&#160;&#160;A. Chortos, J. Liu, Z. Bao,&#160;<i>Nat. Mater.</i>&#160;<b>2016</b>,&#160;<i>15</i>, 937.</p>
<p style="position:absolute;top:149px;left:78px;white-space:nowrap" class="ft124">[98]&#160;&#160;J. Han,&#160;G. Waddington,&#160;R. Adams,&#160;J. Anson,&#160;Y. Liu,&#160;<i>J.&#160;Sport&#160;Health&#160;</i></p>
<p style="position:absolute;top:164px;left:102px;white-space:nowrap" class="ft125"><i>Sci.</i>&#160;<b>2016</b>,&#160;<i>5</i>, 80.</p>
<p style="position:absolute;top:179px;left:78px;white-space:nowrap" class="ft124">[99]&#160;&#160;H. Wang, M. Totaro, L. Beccai,&#160;<i>Adv. Sci.</i>&#160;<b>2018</b>,&#160;<i>5</i>, 1800541.</p>
<p style="position:absolute;top:194px;left:74px;white-space:nowrap" class="ft124">[100]&#160;&#160;T. &#160;Stanko, S. &#160;Hahmann, G.-P. &#160;Bonneau, N. &#160;Saguin-Sprynski,&#160;</p>
<p style="position:absolute;top:209px;left:102px;white-space:nowrap" class="ft125"><i>Comput. Graph.</i>&#160;<b>2017</b>,&#160;<i>66</i>, 74.</p>
<p style="position:absolute;top:224px;left:75px;white-space:nowrap" class="ft124">[101]&#160;&#160;T. &#160;Stanko, N. &#160;Saguin-Sprynski, L. &#160;Jouanet, S. &#160;Hahmann,&#160;</p>
<p style="position:absolute;top:239px;left:102px;white-space:nowrap" class="ft128">G.-P. &#160;Bonneau, presented at&#160;<i>2017 IEEE SENSORS</i>, Glasgow, UK&#160;<br/><b>2017</b>.</p>
<p style="position:absolute;top:269px;left:74px;white-space:nowrap" class="ft124">[102]&#160;&#160;N. &#160;Sprynski, N. &#160;Szafran, B. &#160;Lacolle, L. &#160;Biard,&#160;<i>Comput Aided Des.</i>&#160;</p>
<p style="position:absolute;top:284px;left:102px;white-space:nowrap" class="ft123"><b>2008</b>,&#160;<i>40</i>, 480.</p>
<p style="position:absolute;top:299px;left:74px;white-space:nowrap" class="ft124">[103]&#160;&#160;N. Saguin-Sprynski, L. Jouanet, B. Lacolle, L. Biard, presented at,&#160;</p>
<p style="position:absolute;top:314px;left:102px;white-space:nowrap" class="ft128"><i>EWSHM – 7th European Workshop&#160;on Structural&#160;Health Monitoring</i>,&#160;<br/>Nantes, France&#160;<b>2014</b>.</p>
<p style="position:absolute;top:344px;left:74px;white-space:nowrap" class="ft124">[104]&#160;&#160;S. Kriegman, A. M. Nasab, D. Shah, H. Steele, G. Branin, M. Levin,&#160;</p>
<p style="position:absolute;top:359px;left:102px;white-space:nowrap" class="ft129">J. &#160;Bongard, R. &#160;Kramer-Bottiglio, presented at&#160;<i>2020 IEEE Interna-<br/>tional Conference on Soft Robotics (RoboSoft)</i>,&#160;<b>2020</b>.</p>
<p style="position:absolute;top:389px;left:74px;white-space:nowrap" class="ft124">[105]&#160;&#160;J. &#160;Powers, S. &#160;Kriegman, J. &#160;Bongard,&#160;<i>Artificial Life Conference Pro-</i></p>
<p style="position:absolute;top:404px;left:102px;white-space:nowrap" class="ft125"><i>ceedings</i>, MIT Press, Cambridge, MA, USA&#160;<b>2018</b>, pp. 606–613.</p>
<p style="position:absolute;top:419px;left:74px;white-space:nowrap" class="ft124">[106]&#160;&#160;N. &#160;Jakobi, P. &#160;Husbands, I. &#160;Harvey, In&#160;F. Morán,&#160;A. Moreno,&#160;</p>
<p style="position:absolute;top:419px;left:434px;white-space:nowrap" class="ft124">&#160;</p>
<p style="position:absolute;top:434px;left:102px;white-space:nowrap" class="ft128">J. J. Merelo, P. Chacón (Eds),&#160;<i>Advances in Artificial Life, Lecture Notes&#160;<br/>in Computer Science</i>, Springer, Berlin/Heidelberg, Germany&#160;<b>1995</b>,&#160;<br/>pp. 704–720.</p>
<p style="position:absolute;top:479px;left:74px;white-space:nowrap" class="ft124">[107]&#160;&#160;S. &#160;Koos, J.-B. &#160;Mouret, S. &#160;Doncieux,&#160;<i>IEEE Trans. Evolut. Comput.</i>&#160;</p>
<p style="position:absolute;top:494px;left:102px;white-space:nowrap" class="ft123"><b>2013</b>,&#160;<i>17</i>, 122.</p>
<p style="position:absolute;top:509px;left:74px;white-space:nowrap" class="ft124">[108]&#160;&#160;B. T. Lester, T. Baxevanis, Y. Chemisky, D. C. Lagoudas,&#160;<i>Acta Mech.</i>&#160;</p>
<p style="position:absolute;top:524px;left:102px;white-space:nowrap" class="ft123"><b>2015</b>,&#160;<i>226</i>, 3907.</p>
<p style="position:absolute;top:539px;left:74px;white-space:nowrap" class="ft124">[109]&#160;&#160;W. Huang, Z. Ding, C. Wang, J. Wei, Y. Zhao, H. Purnawali,&#160;<i>Mater.&#160;</i></p>
<p style="position:absolute;top:554px;left:102px;white-space:nowrap" class="ft125"><i>Today</i>&#160;<b>2010</b>,&#160;<i>13</i>, 54.</p>
<p style="position:absolute;top:569px;left:75px;white-space:nowrap" class="ft124">[110]&#160;&#160;I. A. Anderson, T. A. Gisby, T. G. McKay, B. M. O’Brien, E. P. Calius,&#160;</p>
<p style="position:absolute;top:584px;left:102px;white-space:nowrap" class="ft125"><i>J. Appl. Phys.</i>&#160;<b>2012</b>,&#160;<i>112</i>, 041101.</p>
<p style="position:absolute;top:599px;left:76px;white-space:nowrap" class="ft124">[111]&#160;&#160;P. &#160;Boyraz, G. &#160;Runge, A. &#160;Raatz,&#160;<i>Actuators</i>, Vol.&#160;<i>7</i>, Multidisciplinary&#160;</p>
<p style="position:absolute;top:614px;left:102px;white-space:nowrap" class="ft124">Digital Publishing Institute, Basel, Switzerland&#160;<b>2018</b>, p. 48.</p>
<p style="position:absolute;top:629px;left:75px;white-space:nowrap" class="ft124">[112]&#160;&#160;E.&#160;W. &#160;Hawkes,&#160;L.&#160;H. &#160;Blumenschein,&#160;J.&#160;D. &#160;Greer,&#160;A.&#160;M. &#160;Okamura,&#160;</p>
<p style="position:absolute;top:644px;left:102px;white-space:nowrap" class="ft125"><i>Sci. Rob.</i>&#160;<b>2017</b>,&#160;<i>2</i>, eaan3028.</p>
<p style="position:absolute;top:659px;left:75px;white-space:nowrap" class="ft128">[113]&#160;&#160;A. Sadeghi, A. Mondini, B. Mazzolai,&#160;<i>Soft Rob.</i>&#160;<b>2017</b>,&#160;<i>4</i>, 211.<br/>[114]&#160;&#160;R. Deckel, J. B. Wood, Octopus escaping through a 1 inch diameter&#160;</p>
<p style="position:absolute;top:689px;left:102px;white-space:nowrap" class="ft124">hole&#160;<b>2012</b><a href="https://www.youtube.com/watch?v=949eYdEz3Es">, https://www.youtube.com/watch?v</a></p>
<p style="position:absolute;top:688px;left:330px;white-space:nowrap" class="ft124"><a href="https://www.youtube.com/watch?v=949eYdEz3Es">=949eYdEz3Es</a></p>
<p style="position:absolute;top:704px;left:75px;white-space:nowrap" class="ft124">[115]&#160;&#160;T. L. &#160;Buckner, R. &#160;Kramer-Bottiglio,&#160;<i>Multifunct. Mater.</i>&#160;&#160;<b>2018</b>,&#160;&#160;<i>1</i>,&#160;</p>
<p style="position:absolute;top:719px;left:102px;white-space:nowrap" class="ft124">012001.</p>
<p style="position:absolute;top:734px;left:75px;white-space:nowrap" class="ft124">[116]&#160;&#160;M. C. Yuen, R. A. Bilodeau, R. K. Kramer,&#160;<i>IEEE Robot. Autom. Lett.</i>&#160;</p>
<p style="position:absolute;top:749px;left:102px;white-space:nowrap" class="ft123"><b>2016</b>,&#160;<i>1</i>, 708.</p>
<p style="position:absolute;top:764px;left:76px;white-space:nowrap" class="ft124">[117]&#160;&#160;N. &#160;Kazem, T. &#160;Hellebrekers, C. &#160;Majidi,&#160;<i>Adv. Mater.</i>&#160;&#160;<b>2017</b>,&#160;&#160;<i>29</i>,&#160;</p>
<p style="position:absolute;top:779px;left:102px;white-space:nowrap" class="ft124">1605985.</p>
<p style="position:absolute;top:794px;left:75px;white-space:nowrap" class="ft124">[118]&#160;&#160;R. A. Bilodeau, A. M. Nasab, D. S. Shah, R. Kramer-Bottiglio,&#160;<i>Soft&#160;</i></p>
<p style="position:absolute;top:809px;left:102px;white-space:nowrap" class="ft125"><i>Matter</i>, The Royal Society of Chemistry, London, UK&#160;<b>2020</b>.</p>
<p style="position:absolute;top:104px;left:458px;white-space:nowrap" class="ft124">[119]&#160;&#160;N. W. Bartlett, K. P. Becker, R. J. Wood,&#160;<i>Soft Matter</i>&#160;<b>2020</b>,&#160;<i>16</i>, 5871.</p>
<p style="position:absolute;top:119px;left:456px;white-space:nowrap" class="ft124">[120]&#160;&#160;S. Kriegman, N. Cheney, J. Bongard,&#160;<i>Sci. Rep.</i>&#160;<b>2018</b>,&#160;<i>8</i>, 13934.</p>
<p style="position:absolute;top:134px;left:458px;white-space:nowrap" class="ft124">[121]&#160;&#160;W. M. Kier, K. K. Smith,&#160;<i>J. Linn Soc. London Zool.</i>&#160;<b>1985</b>,&#160;<i>83</i>, 307.</p>
<p style="position:absolute;top:149px;left:456px;white-space:nowrap" class="ft124">[122]&#160;&#160;Y. &#160;Yekutieli, R. &#160;Sagiv-Zohar, R. &#160;Aharonov, Y. &#160;Engel, B. &#160;Hochner,&#160;</p>
<p style="position:absolute;top:164px;left:485px;white-space:nowrap" class="ft124">T. Flash,&#160;<i>J. Neurophysiol.</i>&#160;<b>2005</b>,&#160;<i>94</i>, 1443.</p>
<p style="position:absolute;top:179px;left:457px;white-space:nowrap" class="ft124">[123]&#160;&#160;X. Du, H. Cui, T. Xu, C. Huang, Y. Wang, Q. Zhao, Y. Xu, X. Wu,&#160;</p>
<p style="position:absolute;top:194px;left:485px;white-space:nowrap" class="ft125"><i>Adv. Funct. Mater.</i>&#160;<b>2020</b>,&#160;<i>30</i>, 1909202.</p>
<p style="position:absolute;top:209px;left:457px;white-space:nowrap" class="ft124">[124]&#160;&#160;L. Zhang, P. Naumov, X. Du, Z. Hu, J. Wang,&#160;<i>Adv. Mater.</i>&#160;<b>2017</b>,&#160;<i>29</i>,&#160;</p>
<p style="position:absolute;top:224px;left:485px;white-space:nowrap" class="ft124">1702231.</p>
<p style="position:absolute;top:239px;left:456px;white-space:nowrap" class="ft124">[125]&#160;&#160;H.-W. &#160;Huang, M. S. &#160;Sakar, A. J. &#160;Petruska, S. &#160;Pané, B. J. &#160;Nelson,&#160;</p>
<p style="position:absolute;top:254px;left:485px;white-space:nowrap" class="ft125"><i>Nat. Commun.</i>&#160;<b>2016</b>,&#160;<i>7</i>, 12263.</p>
<p style="position:absolute;top:269px;left:456px;white-space:nowrap" class="ft124">[126]&#160;&#160;Y. Wang, H. Cui, Q. Zhao, X. Du,&#160;<i>Matter</i>&#160;<b>2019</b>,&#160;<i>1</i>, 626.</p>
<p style="position:absolute;top:284px;left:457px;white-space:nowrap" class="ft124">[127]&#160;&#160;D. Navarro-Alarcon, Y.-H. Liu,&#160;<i>IEEE Trans. Robot.</i>&#160;<b>2018</b>,&#160;<i>34</i>, 272.</p>
<p style="position:absolute;top:299px;left:456px;white-space:nowrap" class="ft124">[128]&#160;&#160;L. &#160;Ricotti, B. &#160;Trimmer, A. W. &#160;Feinberg, R. &#160;Raman, K. K. &#160;Parker,&#160;</p>
<p style="position:absolute;top:314px;left:485px;white-space:nowrap" class="ft128">R. Bashir, M. Sitti, S. Martel, P. Dario, A. Menciassi,&#160;<i>Sci. Rob.</i>&#160;<b>2017</b>,&#160;<br/><i>2</i>, eaaq0495.</p>
<p style="position:absolute;top:344px;left:456px;white-space:nowrap" class="ft124">[129]&#160;&#160;J.&#160;W. &#160;Boley,&#160;W.&#160;M. v. &#160;Rees,&#160;C. &#160;Lissandrello,&#160;M.&#160;N. &#160;Horenstein,&#160;</p>
<p style="position:absolute;top:359px;left:485px;white-space:nowrap" class="ft129">R. L. &#160;Truby, A. &#160;Kotikian, J. A. &#160;Lewis, L. &#160;Mahadevan,&#160;<i>Proc. Natl.&#160;<br/>Acad. Sci.</i>&#160;<b>2019</b>,&#160;<i>116</i>, 201908806.</p>
<p style="position:absolute;top:389px;left:457px;white-space:nowrap" class="ft124">[130]&#160;&#160;A. S. &#160;Gladman, E. A. &#160;Matsumoto, R. G. &#160;Nuzzo, L. &#160;Mahadevan,&#160;</p>
<p style="position:absolute;top:404px;left:485px;white-space:nowrap" class="ft124">J. A. Lewis,&#160;<i>Nat. Mater.</i>&#160;<b>2016</b>,&#160;<i>15</i>, 413.</p>
<p style="position:absolute;top:419px;left:458px;white-space:nowrap" class="ft124">[131]&#160;&#160;M. Manti, V. Cacucciolo, M. Cianchetti,&#160;<i>IEEE Robot. Autom.</i>&#160;<b>2016</b>,&#160;</p>
<p style="position:absolute;top:434px;left:485px;white-space:nowrap" class="ft125"><i>23</i>, 93.</p>
<p style="position:absolute;top:449px;left:458px;white-space:nowrap" class="ft124">[132]&#160;&#160;E. &#160;Steltz, A. &#160;Mozeika, N. &#160;Rodenberg, E. &#160;Brown, H. M. &#160;Jaeger,&#160;</p>
<p style="position:absolute;top:449px;left:816px;white-space:nowrap" class="ft124">&#160;</p>
<p style="position:absolute;top:464px;left:485px;white-space:nowrap" class="ft128">presented at&#160;<i>2009 IEEE/RSJ Int. Conf. Intelligent Robots and Systems</i>,&#160;&#160;<br/>St. Louis, MO, USA&#160;<b>2009</b>.</p>
<p style="position:absolute;top:494px;left:457px;white-space:nowrap" class="ft124">[133]&#160;&#160;T. L. Buckner, E. L. White, M. C. Yuen, R. A. Bilodeau, R. K. Kramer,&#160;</p>
<p style="position:absolute;top:509px;left:485px;white-space:nowrap" class="ft129">presented at&#160;<i>2017 IEEE/RSJ Int. Conf. Intelligent Robots and Systems&#160;<br/>(IROS)</i>, Vancouver, Canada&#160;<b>2017</b>.</p>
<p style="position:absolute;top:539px;left:457px;white-space:nowrap" class="ft124">[134]&#160;&#160;S. Narang &#160;Yashraj, J. Vlassak &#160;Joost, D. Howe &#160;Robert,&#160;<i>Adv. Funct.&#160;</i></p>
<p style="position:absolute;top:554px;left:485px;white-space:nowrap" class="ft125"><i>Mater.</i>&#160;<b>2018</b>,&#160;<i>28</i>, 1707136.</p>
<p style="position:absolute;top:569px;left:457px;white-space:nowrap" class="ft124">[135]&#160;&#160;S. &#160;Kawamura,&#160;T. &#160;Yamamoto,&#160;D. &#160;Ishida,&#160;T. &#160;Ogata,&#160;Y. &#160;Nakayama,&#160;</p>
<p style="position:absolute;top:584px;left:485px;white-space:nowrap" class="ft128">O. Tabata, S. Sugiyama, presented at&#160;<i>Proc. 2002 IEEE International&#160;<br/>Conference on Robotics and Automation (Cat. No.02CH37292)</i>,&#160;<br/>Washington, DC, USA&#160;<b>2002</b>.</p>
<p style="position:absolute;top:629px;left:457px;white-space:nowrap" class="ft124">[136]&#160;&#160;T.&#160;L. &#160;Buckner,&#160;M.&#160;C. &#160;Yuen,&#160;S.&#160;Y. &#160;Kim,&#160;R. &#160;Kramer-Bottiglio,&#160;<i>Adv.&#160;</i></p>
<p style="position:absolute;top:644px;left:485px;white-space:nowrap" class="ft125"><i>Funct. Mater.</i>&#160;<b>2019</b>,&#160;<i>29</i>, 1903368.</p>
<p style="position:absolute;top:659px;left:457px;white-space:nowrap" class="ft124">[137]&#160;&#160;Y. J. Kim, S. Cheng,&#160;S. Kim,&#160;K. Iagnemma,&#160;<i>IEEE&#160;Trans.&#160;Robot.</i>&#160;<b>2013</b>,&#160;</p>
<p style="position:absolute;top:674px;left:485px;white-space:nowrap" class="ft125"><i>29</i>, 1031.</p>
<p style="position:absolute;top:689px;left:457px;white-space:nowrap" class="ft124">[138]&#160;&#160;M. &#160;Cianchetti,&#160;T. &#160;Ranzani,&#160;G. &#160;Gerboni,&#160;T. &#160;Nanayakkara,&#160;</p>
<p style="position:absolute;top:704px;left:485px;white-space:nowrap" class="ft124">K. Althoefer, P. Dasgupta, A. Menciassi,&#160;<i>Soft Rob.</i>&#160;<b>2014</b>,&#160;<i>1</i>, 122.</p>
<p style="position:absolute;top:719px;left:457px;white-space:nowrap" class="ft128">[139]&#160;&#160;C. Fields, M. Levin,&#160;<i>WIREs Systems Biol. Med.</i>&#160;<b>2018</b>,&#160;<i>10</i>, e1410.<br/>[140]&#160;&#160;M. A. McEvoy, N. Correll,&#160;<i>Science</i>&#160;<b>2015</b>,&#160;<i>347</i>, 1261689.</p>
<p style="position:absolute;top:749px;left:459px;white-space:nowrap" class="ft124">[141]&#160;&#160;D. J. Preston, P. Rothemund, H. J. Jiang, M. P. Nemitz, J. Rawson,&#160;</p>
<p style="position:absolute;top:764px;left:485px;white-space:nowrap" class="ft128">Z. &#160;Suo, G. M. &#160;Whitesides,&#160;<i>Proc. Natl. Acad. Sci. USA</i>&#160;&#160;<b>2019</b>,&#160;&#160;<i>116</i>,&#160;&#160;<br/>7750.</p>
<p style="position:absolute;top:794px;left:457px;white-space:nowrap" class="ft124">[142]&#160;&#160;S. &#160;Wang, L. &#160;Liu, J. &#160;Liu, W. &#160;Zhu, Y. &#160;Tanizaki, L. &#160;Fu, L. &#160;Bao, Y. &#160;Shi,&#160;</p>
<p style="position:absolute;top:809px;left:485px;white-space:nowrap" class="ft124">J. Jiang,&#160;<i>Front. Endocrinol.</i>&#160;<b>2019</b>,&#160;<i>10</i>, 11.</p>
<p style="position:absolute;top:1112px;left:72px;white-space:nowrap" class="ft126"><i>Adv.</i>&#160;<i>Mater.</i>&#160;<b>2020</b>, 2002882</p>
</div>
</body>
</html>
